[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "QM2-Tutorium WiSe23/24",
    "section": "",
    "text": "Allgemeines\nHerzlich Willkommen zum QM2-Tutorium! In diesem Semester lernt ihr alles rund um‚Äôs Thema Bayes-Statistik. Wie auch im letzten Tutorium findet ihr hier s√§mtliche Lehrmaterialien wie Aufgaben samt L√∂sungen, Fallstudien, wichtige Befehle und n√ºtzliche Links.\nWir w√ºnschen euch viel Erfolg!\nLiebe Gr√º√üe,\nEmilia und Raphael"
  },
  {
    "objectID": "Theoriestunde.html#bayes-am-baumdiagramm",
    "href": "Theoriestunde.html#bayes-am-baumdiagramm",
    "title": "1¬† Bayes-Theorem",
    "section": "1.1 Bayes am Baumdiagramm",
    "text": "1.1 Bayes am Baumdiagramm\n\n1.1.1 Herleitung\nDer Satz von Bayes ist das zentrale mathematische Theorem, auf dem alle Inhalte des Moduls aufbauen. Deshalb kann es hilfreich sein, ihn in seinen Grundz√ºgen und seiner Anwendung auf komplexere Sachverhalte zu verstehen. Hierzu m√ºssen wir aber von ganz unten anfangen, n√§mlich bei den guten alten Baumdiagrammen. Gehen wir davon aus, dass wir eine Formel erarbeiten m√∂chten, mit der wir jede bedingte Wahrscheinlichkeit eines binomialverteilten Sachverhalts ausrechnen k√∂nnen:\n Multipliziert man \\(P(A)\\) mit der Wahrscheinlichkeit f√ºr \\(B\\), under der Bedingung dass \\(A\\) bereits eingetreten ist, also \\(P(B|A)\\), so erh√§lt man die Schnittwahrscheinlichkeit von \\(A\\) und \\(B\\), n√§mlich \\(P(A\\cap B)\\). Als n√§chstes schauen wir uns das umgekehrte Baumdiagramm an. Multipliziert man \\(P(B)\\) mit der bedingten Wahrscheinlichkeit \\(P(A|B)\\), so erh√§lt man ebenfalls die Schnittwahrscheinlichkeit von \\(A\\) und \\(B\\). Diese zwei Produkte k√∂nnen wir also gleich setzen: \\[\nP(A)\\times P(B|A)=P(B)\\times P(A|B)\n\\] Jetzt m√ºssen wir nur noch nach der gew√ºnschten Wahrscheinlichkeit aufl√∂sen, zum Beispiel nach \\(P(B|A)\\): \\[\nP(A)\\times P(B|A)=P(B)\\times P(A|B)\\ |:P(A)\n\\] \\[\nP(B|A)=\\dfrac{P(B)\\times P(A|B)}{P(A)}\n\\] Da haben wir auch schon unsere Formel. Diese Formel nennt man auch das Bayes-Theorem.\n\n\n1.1.2 Beipsiel: Brustkrebsdiagnose\nGehen wir davon aus, dass Anna mit Brustkrebs diagnostiziert wurde und jetzt unbedingt wissen m√∂chte, wie hoch die Wahrscheinlichkeit ist, dass sie auch wirklich Brustrebs hat. Dieser Zusammenhang l√§sst sich in einem Baumdiagramm darstellen:  Hier sehen wir unter anderem, wie wahrscheinlich es ist, Brustkrebs zu bekommen: \\(P(B)=0,01\\). Au√üerdem k√∂nnen wir die bedingte Wahrscheinlichkeit \\(P(P|B)=0,8\\) ablesen, also die Wahrscheinlichkeit daf√ºr, positiv diagnostiziert zu werden, unter der Voraussetzung dass man Brustkrebs hat. \\(P(\\bar{P}|B)\\) ist wiederum die Wahrscheinlichkeit f√ºr den Fall, dass man Brustkrebs hat, dieser jedoch vom Test nicht erkannt wird. Die Wahrscheinlichkeit, die uns eigentlich interessiert, n√§mlich \\(P(B|P)\\) ist hier aber gar nicht abgebildet; um diese abzulesen, br√§uchte es das umgekehrte Baumdiagramm. Um Annas dringende Frage zu beantworten, haben wir allerdings schon alle Informationen, denn wir machen uns einfach das Bayes-Theorem zu Nutze. Wir k√∂nnen die Gleichung von vorhin einfach auf diese Situation anwenden, weil wir ja wissen, dass \\(P(B\\cap P)\\) gleich \\(P(P\\cap B)\\) ist: \\[\nP(P)\\times P(B|P)=P(B)\\times P(P|B)\n\\] Jetzt k√∂nnen wir nach \\(P(B|P)\\) aufl√∂sen: \\[\nP(P)\\times P(B|P)=P(B)\\times P(P|B)\\ |:P(P)\n\\] \\[\nP(B|P)=\\dfrac{P(B)\\times P(P|B)}{P(P)}\n\\] Jetzt m√ºssen wir nur noch die Wahrscheinlichkeiten einsetzen. \\(P(B)\\) und \\(P(P|B)\\) wissen wir ja bereits und die Gesamtwahrscheinlichkeit von \\(P\\) k√∂nnen wir auch ganz einfach ausrechnen, indem wir die Schnittwahrscheinlichkeiten \\(P(P\\cap B)\\) und \\(P(P\\cap \\bar B)\\) addieren: \\[\nP(B|P)=\\dfrac{P(B)\\times P(P|B)}{P(B)\\times P(P|B) + P(\\bar B)\\times P(P|\\bar B)}\n\\] \\[\nP(B|P)=\\dfrac{0,01\\times 0,8}{0,01\\times 0,8 + 0,99\\times 0,1}\n\\] \\[\nP(B|P)=\\dfrac{0,008}{0,107}\n\\] \\[\nP(B|P)=0,0747\n\\] Geschafft! Wir haben erfolgreich herausgefunden, wie wahrscheinlich es ist, dass Anna richtigerweise mit Brustkrebs diagnostiziert wurde. Mit anderen Worten: Wir haben die Wahrscheinlichkeit f√ºr eine Hypothese, n√§mlich dass sie Brustkrebs hat, unter Einbeziehung einer bestimmten Datenlage (Evidenz), n√§mlich dass ihr ein positives Testergebnis vorliegt. Um die Wahrscheinlichkeit f√ºr diese Hypothese auszurechnen, haben wir unser Vorwissen, n√§mlich die Wahrscheinlichkeit daf√ºr, √ºberhaupt Brustkrebs zu haben (Prior) mit der Wahrscheinlichkeit, positiv diagnostiziert zu werden, unter der Bedingung dass man Brustkrebs hat (Likelihood) multipliziert und dieses Produkt durch die gesamte Evidenz geteilt. Als Formel sieht das dann so aus: \\[\nP(H|E)=\\dfrac{Prior\\times Likelihood}{Evidenz}\n\\] Mit dieser allgemeinen Bayes-Formel kann man alle m√∂glichen Hypothesen testen. Sie wird in den verschiedensten wissenschaftlichen Bereichen angewendet, um weitaus komplexere Sachverhalte als einen binomialverteilten Zusammenhang zu verstehen. Man kann auch eine ganze Reihe von Hypothesen testen, um danach festzustellen, welche Hypothese die wahrscheinlichste ist. Das tun wir zum Beispiel, wenn wir eine Bayes-Box erstellen."
  },
  {
    "objectID": "Theoriestunde.html#globusversuchgittermethode",
    "href": "Theoriestunde.html#globusversuchgittermethode",
    "title": "1¬† Bayes-Theorem",
    "section": "1.2 Globusversuch/Gittermethode",
    "text": "1.2 Globusversuch/Gittermethode\nBeim Globusversuch wollen wir zum Beispiel wissen, wie wahrscheinlich es ist, dass der Globus 6 mal auf Wasser (W) und 3 mal auf Land (L) zu landen, also wie wahrscheinlich 6 von 9 Treffern sind. Um das herauszufinden, stellen wir mehrere Hypothesen f√ºr die Trefferwahrscheinlichkeit auf, um genau zu sein 11 (jede Trefferwahrscheinlichkeit von 0 bis 1 mit einer Schrittweite von 0,1). Diese Wahrscheinlichkeiten setzen wir dann einzeln in das Bayes-Theorem ein. Beispiel: Wir m√∂chten die Wahrscheinlichkeit f√ºr die Hypothese testen, dass die Trefferwahrscheinlichkeit p 0,6 betr√§gt und ber√ºcksichtigen dabei die Datenlage/Evidenz, dass wir 6 von 9 Treffern beobachtet haben. Unser Vorwissen h√§lt sich dazu in Grenzen, weshalb wir diesen Faktor nicht mit einflie√üen lassen. Wir errechnen also lediglich den Likelihood, n√§mlich die Wahrscheinlichkeit daf√ºr, dass wir 6 von 9 Treffern beobachten, falls die Trefferwahrscheinlichkeit wirklich bei 0,6 liegt: \\[\nP(p = 0,6|6\\ von\\ 9\\ Treffern) = P(6,9|p=0,6)\n\\] Man k√∂nnte auch sagen, dass man als Prior 1 nimmt, denn \\(1\\times Likelihood\\) ist einfach nur der Likelihood. Damit sich alle Postwahrscheinlichkeiten zu 1 aufsummieren, teilen wir den Likelihood durch die Evidenz, also die Summe aller unstandardisierten Postwahrscheinlichkeiten. Wenn wir diese Postwahrscheinlichkeit f√ºr alle 11 Hypothesen ausrechnen, sieht das dann in Tabellenform so aus:\n\n  tibble(\n    Hypothesen = seq(0, 1, by = 0.1),\n    Prior = 1,\n    Likelihood = dbinom(6, 9, Hypothesen),\n    Evidenz = sum(Prior * Likelihood),\n    Post = (Prior * Likelihood / Evidenz)\n    ) %&gt;% \n  mutate(Post = round(Post, 2))\n\n\n\n  \n\n\n\nDer aufmerksame Leser hat im R-Code den Satz des Bayes wiedererkannt, der zur Berechnung der Postwahrscheinlichkeit genutzt wird. Die Formel f√ºr die Berechnung der relativen Wahrscheinlichkeiten aller Hypothesen (Trefferwahrscheinlichkeiten f√ºr n-mal Wasser und n-mal Land) sieht so aus: \\[\nP(p|W,L)=\\dfrac{P(p)\\times P(W,L|p)}{P(W,L)}\n\\]"
  },
  {
    "objectID": "Theoriestunde.html#bayesianische-lineare-regression",
    "href": "Theoriestunde.html#bayesianische-lineare-regression",
    "title": "1¬† Bayes-Theorem",
    "section": "1.3 Bayesianische lineare Regression",
    "text": "1.3 Bayesianische lineare Regression\nEinn weitere Methode, bei der das Bayes-Theorem Anwendung findet, ist die lineare Regression. Dieses Thema sollte noch aus der Schule und Statstik 1 ausreichend bekannt sein. Hier trotzdem nochmal die Formel:\n\\[\ny_{i}=\\alpha+\\beta x_{i}\n\\] Jeder Wert f√ºr \\(y\\) (das bedeutet das Index \\(i\\)) ist das Ergebnis des Achsenabschnitts \\(\\alpha\\) plus der Steigung \\(\\beta\\) mal den jeweiligen \\(x\\)-Wert. Jedem \\(x\\)-Wert entspricht also einem \\(y\\)-Wert. So sieht das ganze dann anhand des Kung-Datensatzes aus, wenn \\(y\\) K√∂rpergr√∂√üe und \\(x\\) K√∂rpergewicht ist:\n\n\n\n\n\nDer y-Achsenabschnitt sagt uns jetzt aber nur aus, wie gro√ü ein Mensch mit dem Gewicht von 0 kg ist. Um sinnvolle Priors zu formulieren, ist es hilfreich, direkt ein Modell aufzustellen, das mit dem zentrierten K√∂rpergewicht arbeitet, denn wenn wir von allen Gewichten den Mittelwert abziehen, wird der Mittelwert an die Stelle, an der 0 war, verschoben. Dadurch zeigt der y-Achsenabschnitt die K√∂rpergr√∂√üe eines durchschnittlich schweren Kung an:\n\n\n\n\n\nJetzt kommt Bayes in‚Äôs Spiel. Bei der Bayesianischen linearen Regression gehen wir nicht davon aus, dass der einzige und einzig wahre \\(y\\)-Wert das Ergebnis der Formel ist, sondern dass es lediglich der Mittelwert der Postverteilung ist. Es wird also kein Punktsch√§tzer abgegeben, sondern ein Wertebereich, in dem \\(y\\) liegt. Das Ergebnis von \\(\\alpha+\\beta x_{i}\\) ist der Mittelwert \\(\\mu\\) dieses Wertebereichs. Au√üerdem gehen wir apriori davon aus, dass dieser Wertebereich eine Normalverteilung mit Mittellwert \\(\\mu\\) und Streuung \\(\\sigma\\) ist. Man sagt auch \\(y\\) ist normalverteilt (Bei K√∂rpergr√∂√üe durchaus eine vern√ºnftige Annahme). \\[\n\\begin{aligned}\ny_i\\sim Normal(\\mu_{i},\\sigma)\\\\\n\\mu_{i}=\\alpha+\\beta x_{i}\n\\end{aligned}\n\\] Um noch mehr Vorwissen in die Regression einflie√üen zu lassen, spezifizieren wir die Modellparameter in Form des Priors. Wir k√∂nnen n√§mlich unser Vorwissen zur K√∂rpergr√∂√üe eines durchschnittlich schweren Kung angeben. Wir gehen davon aus, dass diese K√∂rpergr√∂√üe bei ca. 140 cm liegt, aber auch ein bisschen dar√ºber oder darunter liegen kann. Um diese Unsicherheit zu quantifizieren, geben wir eine Verteilung mit einer sinnvollen Streuung an, zum Beispiel \\(N(140, 10)\\). Au√üerdem gehen wir von einer positiven linearen Beziehung aus, also dass ein Mensch mit h√∂herem Gewicht auch gr√∂√üer ist. Das hei√üt, um den besten Wert f√ºr die Steigung \\(\\beta\\) zu bestimmen, wollen wir m√∂gliche Werte aus einer Verteilung ziehen, die nur positive Werte zul√§sst, wie zum Beispiel \\(N(5,3)\\). Die Streuung \\(\\sigma\\) muss auch zwingend positiv sein, weil es keine negative Streuung geben kann. Deshalb ziehen wir hier aus einer Exponentialverteilung. Unsere Modellspezifikation sieht also wie folgt aus: \\[\n\\begin{aligned}\ny_i\\sim Normal(\\mu_{i},\\sigma)\\\\\n\\mu_{i}=\\alpha+\\beta x_{i}\\\\\n\\alpha \\sim Normal(140, 10)\\\\\n\\beta \\sim Normal(5,3)\\\\\n\\sigma \\sim Exp(0.1)\n\\end{aligned}\n\\] Nun haben wir alle Prior-Parameter festgelegt. Aber was bedeutet das genau? Wir haben jetzt quasi einen Topf voll Zutaten, aus dem wir zuf√§llig irgendwelche Zutaten ziehen und zusammenmischen. Zum Beispiel k√∂nnte ein Gericht, was dann ensteht, folgende Gleichung sein: \\[\n\\begin{aligned}\ny_i\\sim Normal(\\mu_{i},10)\\\\\n\\mu=148+3x\n\\end{aligned}\n\\] Wenn man jetzt einen Wert f√ºr \\(x\\) einsetzt, zum Beispiel 4 (Reminder: wir arbeiten mit zentrierten Werten), dann bekommt man einen \\(y\\)-Wert, n√§mlich 160, heraus. Weil wir aber nicht nur ein zuf√§lliges Gericht zusammenw√ºrfeln, sondern ganz viele (ca. 4000), bekommen wir eben eine Normalverteilung f√ºr jeden einzelnen \\(x\\)-Wert heraus, die alle m√∂glichen Kombinationen unserer Zutaten aus dem Topf enth√§lt. Die gr√ºne Gerade ist also nicht die einzige, sondern die Gerade der Mittelwerte dieser Verteilungen. Der graue Bereich um die Gerade herum ist der Bereich, in dem 95 Prozent aller anderen Geraden liegen:\n\n\n\n\n\nJedes Gericht, was aus einer zuf√§lligen Ziehung aus dem Topf entsteht, ist eine Hypohtese. Wie immer wollen wir nat√ºrlich eine Hypothese unter Einbeziehung von Daten √ºberpr√ºfen. In diesem Fall sind die Daten das Gewicht und die Gr√∂√üe der Kung-Menschen. Um die Wahrscheinlichkeit f√ºr jede m√∂gliche Kombination aller m√∂glichen Modellparameter auszurechnen, multiplizieren wir wieder unser Vorwissen, also die Modellspezifikation mit dem Likelihood, also der Wahrscheinlichkeit, die Kung-Daten zu beobachten, unter der Bedingung dass unsere Priors zutreffen. Dann teilt man noch durch die Evidenz, also unsere Daten. Das ist quasi die Endform des Bayes-Theorems, aus dessen Postverteilung dann Stichproben f√ºr unseren stan_glm gezogen werden: \\[\nP(\\alpha, \\beta, \\sigma |H,W) = \\dfrac{P(\\alpha, \\beta, \\sigma)\\times P(H,W|\\alpha, \\beta, \\sigma)}{P(H,W)}\n\\]"
  },
  {
    "objectID": "DAGs.html#die-vier-atome-der-kausalanalyse",
    "href": "DAGs.html#die-vier-atome-der-kausalanalyse",
    "title": "2¬† Theorie zu DAGs",
    "section": "2.1 Die vier Atome der Kausalanalyse",
    "text": "2.1 Die vier Atome der Kausalanalyse\n\n\n\n\n\nFigure¬†2.1: Die vier Atome der Kausalinferenz\n\n\n\n\nAufgabe: Von x zu y, also die Wirkung von X auf Y\n\n2.1.1 Die Konfundierung\nGabel, von einem Punkt gehen 2 Pfeile aus\nüö∂&lt;‚Äî‚Äî‚Äî- üï≥ ‚Äî‚Äî‚Äî‚Äì&gt; üèÅ\nx &lt;‚Äî‚Äî‚Äî- z ‚Äî‚Äî‚Äî‚Äì&gt; y\n          üåâ \nVorstellung: Wir haben einen Pfad, der bei X startet und √ºber z zu y f√ºhrt. Man stelle sich vor, an der Stelle von z sei ein Loch, durch das Kontrollieren bauen wir eine Br√ºcke bzw. schlie√üen das Loch.\n‚Äì&gt; Damit schlie√üt sich der Pfad\n\n\n2.1.2 Die Kollision\n2 Pfeile treffen an einem Punkt aufeinander\nüö∂‚Äî‚Äî‚Äî-&gt;üí£&lt;‚Äî‚Äî‚Äî‚Äìüö´\nx‚Äî‚Äî‚Äî-&gt; m &lt;‚Äî‚Äî‚Äî‚Äì y\n          üåã\nVorstellung: Wir haben einen Pfad, der bei X startet und √ºber m zu y f√ºhrt. Man stelle sich vor, an der Stelle von m explodiert die Stra√üe (= Kollision), was tun wir jetzt? Wenn wir versuchen die Stra√üe zu reparieren, also zu kontrollieren, explodiert m immer wieder, wir k√∂nnen uns vorstellen, dass z.B. ein Vulkan an der Stelle immer wieder ausbricht.\n‚Äì&gt; Hier d√ºrfen wir auf keinen Fall kontrollieren, in diesem Fall lassen wir alles so, wie es ist."
  },
  {
    "objectID": "DAGs.html#beispielaufgabe",
    "href": "DAGs.html#beispielaufgabe",
    "title": "2¬† Theorie zu DAGs",
    "section": "2.2 Beispielaufgabe",
    "text": "2.2 Beispielaufgabe\n\n\n\n\n\nGegeben sei der DAG g (s. u.). Der DAG verf√ºgt √ºber r dag_size Variablen, die als Knoten im Graph dargestellt sind (mit \\(x_1, x_2, \\ldots x_n\\) bezeichnet) und √ºber Kanten verbunden sind.\nWelche minimale Variablenmenge muss kontrolliert werden, um den kausalen Effekt von der UV zur AV zu identifizieren?\nUV: x4.\nAV: x5.\nHinweise:\n\nMengen sind mittels geschweifter Klammern gekennzeichnet, z.B. {x8, x9} meint die Menge mit den zwei Elementen x8 und x9.\nDie leere Menge { } bedeutet, dass keine Variable kontrolliert werden muss, um den kausalen Effekt zu identifizieren.\nAlle Variablen werden als gemessen vorausgesetzt.\nEs ist m√∂glich, dass es keine L√∂sung gibt, dass es also keine Adjustierungsmenge gibt, um den kausalen Effekt zu identifizieren. Wenn dies der Fall sein sollte, w√§hlen Sie ‚Äúkeine L√∂sung‚Äù.\nEs ist m√∂glich, dass einzelne Variablen keine Kanten besitzen, also keine Verbindung zu anderen Variablen (Knoten) haben.\n\nVorgehen:\n\nUV & AV identifizieren\n\nUV ist bei diesem DAG x4 und die AV ist x5\n\nDirekte kausale Pfade suchen\n\nIn diesem DAG gibt es keine direkten kausalen Pfade, also keine Pfeile, die direkt von x4 zu x5 f√ºhren, bei denen die Pfeilrichtung korrekt ist und es √ºber keine weiteren Variablen geht.\n\nM√∂gliche Hinterpfade suchen\n\nDieser DAG hat viele Hinterpfade, also Pfade, die von der UV √ºber weitere Variablen zur AV f√ºhren.\nEin Beispiel w√§re der Pfad von x4 √ºber x3, x1, x2 zu x5. Nat√ºrlich gibt es noch viel mehr M√∂glichkeiten.\n\nWelche Pfade soll man schlie√üen (= Konfundierung), welche soll man lassen (= Kollision)?\n\nWichtig ist es hierbei jeden Pfad einzeln f√ºr sich zu betrachten und nur bei dem zu betrachtenden Pfad auf die Pfeilrichtungen zu schauen.\nBetrachtet man nun die Variable x7, dann sieht man, dass egal welchen Pfad man geht, bei x7 immer eine Kollision entsteht. Also kann man alle Pfade, die √ºber x7 f√ºhren ausschlie√üen und es darf nicht kontrolliert werden. x6 ist damit auch ein Collider, da der einzige Pfad, der keine Kollision bei x6 hat √ºber x7 f√ºhrt, damit ist auch diese Variable ausgeschlossen.\nSuchen wir jetzt nach Confundern: Je nach Pfad, den man w√§hlt kann jede andere Variable, also x1, x2 und x3 (denn UV und AV darf man nie kontrollieren), ein Confunder sein.\nSchauen wir uns ein Beispiel an: x4 &lt;- x1 -&gt; x2 -&gt; x5 Bei diesem Pfad w√§re x1 der Confunder.\n Alle Pfade mit Kollisionen sind hier rot gekennzeichnet, alle mit Confundern gr√ºn.\n\nDie kleinste Menge finden\n\nWie finden wir jetzt die minimale Menge an Variablen, die wir kontrollieren m√ºssen, um alle Hintert√ºrpfade zu schlie√üen?\nDas Gute ist, dass sobald man einen Confunder auf einem Pfad hat, es total egal ist, welche ‚ÄúZwischen‚Äù-Variable man kontrolliert.\nHier anhand eines Beispiels: x4 &lt;- x1 -&gt; x2 -&gt; x5 Bei diesem Pfad w√§re x1 zwar der Confunder, aber wir k√∂nnen stattdessen auch x2 kontrollieren, da es f√ºr den Pfad und das Ergebnis egal ist, ob wir x1 oder x2 kontrollieren.\nGenauso egal ist es, welchen Confunder man kontrolliert, wenn man mehrere Confunder auf einem Pfad hat, es reicht immer, nur einen zu kontrollieren.\nSchauen wir jetzt, √ºber welche ‚ÄúZwischen‚Äù-Variable alle Confunder-Pfade laufen m√ºssen: in diesem Fall w√§re das x2, also reicht es nur diese Variable zu kontrollieren, um alle Hintert√ºrpfade zu schlie√üen und den Effekt der UV auf die AV zu identifizieren."
  },
  {
    "objectID": "DAGs.html#kausal03",
    "href": "DAGs.html#kausal03",
    "title": "2¬† Theorie zu DAGs",
    "section": "2.3 kausal03",
    "text": "2.3 kausal03\n\nAL\n\n\nGegeben sei der DAG g (s.u.). Was ist die minimale Menge an Variablen, die man kontrollieren muss, um den kausalen Effekt von x auf y zu identifizieren?\n\n\n\n\n\nHinweise:\n\nGebogene Kurven mit doppelter Pfeilspitze zeigen keine Kausaleinfl√ºsse ein (was in DAGs nicht erlaubt w√§re).\nStattdessen zeigen Sie eine Assoziation bedingt durch eine (nicht aufgef√ºhrte) Konfundierungsvariable an.\n\n\n2.4 Answerlist\n\n{ w1, w2, z2 }\n{ w2, z2 }\n{ w1, w2 }\n{ w1, z2 }\n{ w1 }\n\n\n\n\nWir haben einen direkten kausalen Pfad zwischen x und y Ignorieren wir erstmal die gebogenen Pfeile und schauen uns dann zu allererst die Pfade an, die nur √ºber eine Zwischenvariable f√ºhren. Hier sehen wir, dass es nur 2 M√∂glichkeiten gibt, einmal √ºber w1 und √ºber w2, beides sind Confunder, also m√ºssen wir beide auf jeden Fall kontrollieren.\nWir haben 2 Collider Pfade, einmal von x √ºber w1, z1, v, z2 zu y und von x √ºber z1, v, z2, w2 zu y (w√ºrden wir die beiden Pfade zu einem gro√üen kombinieren h√§tten wir theoretisch sogar noch einen Collider-Pfad). Diese Pfade k√∂nnen wir also von unseren √úberlegungen ausschlie√üen.\nSuchen wir jetzt noch nach Confunder-Pfaden, die nicht √ºber w1 oder w2 f√ºhren. Es bleibt nur ein Pfad √ºbrig (von x √ºber z1, v, z2 zu y). Der Confunder w√§re hier v, jedoch gibt es diese Antwortm√∂glichkeit nicht. Wie jedoch vorher erkl√§rt, ist es egal welche Zwischenvariable wir auf einem Confunder-Pfaf kontrollieren, hauptsachen wir kontrollieren eine. F√ºr diesen Pfad ist es also egal, ob wir z1, v oder z2 kontrollieren.\nDie L√∂sung w√§re also: { w1, w2, z2 }\nGenauso richtig w√§re aber auch: { w1, w2, z1 } { w1, w2, v }"
  },
  {
    "objectID": "DAGs.html#answerlist",
    "href": "DAGs.html#answerlist",
    "title": "2¬† Theorie zu DAGs",
    "section": "2.4 Answerlist",
    "text": "2.4 Answerlist\n\n{ w1, w2, z2 }\n{ w2, z2 }\n{ w1, w2 }\n{ w1, z2 }\n{ w1 }"
  },
  {
    "objectID": "DAGs.html#kausal29",
    "href": "DAGs.html#kausal29",
    "title": "2¬† Theorie zu DAGs",
    "section": "2.5 kausal29",
    "text": "2.5 kausal29\n\nAL\n\n\nGegeben sei der DAG (Graph) g (s. u.). Der DAG verf√ºgt √ºber mehrere Variablen, die als Knoten im Graph dargestellt sind.\n\nf &lt;-\n  dagify(\n    y ~ z + m,\n    m ~ x + z,\n    exposure = \"x\",\n    outcome = \"y\"\n  )\n\nHier ist die Definition des DAGs:\n\ncat(f)\n\ndag {\nm\nx [exposure]\ny [outcome]\nz\nm -&gt; y\nx -&gt; m\nz -&gt; m\nz -&gt; y\n}\n\n\nUnd so sieht er aus:\n\nggdag(f) + theme_dag_blank()\n\n\n\n\nWelche minimale Variablenmenge muss kontrolliert werden, um den kausalen Effekt von der UV zur AV zu identifizieren?\nUV: x\nAV: y\nHinweise:\n\nMengen sind mittels geschweifter Klammern gekennzeichnet, z.B. {x8, x9} meint die Menge mit den zwei Elementen x8 und x9.\nDie leere Menge { } bedeutet, dass keine Variable kontrolliert werden muss, um den kausalen Effekt zu identifizieren.\nAlle Variablen werden als gemessen vorausgesetzt.\nEs ist m√∂glich, dass es keine L√∂sung gibt, dass es also keine Adjustierungsmenge gibt, um den kausalen Effekt zu identifizieren. Wenn dies der Fall sein sollte, w√§hlen Sie ‚Äúkeine L√∂sung‚Äù.\n\n\n2.6 Answerlist\n\n{m}\n{z}\n{m, z}\n{ }\nkeine L√∂sung\n\n\n\n\nMan sieht direkt, dass man immer √ºber m gehen muss, um zu y zu gelangen. Betrachtet man den Pfad von x √ºber m zu y, dann sieht man, dass m hier ein Mediator ist, diese muss man nicht kontrollieren. Der zweite m√∂gliche Pfad f√ºhrt √ºber m und z, jedoch liegt hier bei m ein Collider vor, deswegen d√ºrfen wir in dem Fall weder m noch z kontrollieren.\nDie L√∂sung ist also: { }, da wir keine Variable kontrollieren m√ºssen, um den Effekt von x auf y zu identifizieren."
  },
  {
    "objectID": "DAGs.html#answerlist-1",
    "href": "DAGs.html#answerlist-1",
    "title": "2¬† Theorie zu DAGs",
    "section": "2.6 Answerlist",
    "text": "2.6 Answerlist\n\n{m}\n{z}\n{m, z}\n{ }\nkeine L√∂sung"
  },
  {
    "objectID": "DAGs.html#kausal28",
    "href": "DAGs.html#kausal28",
    "title": "2¬† Theorie zu DAGs",
    "section": "2.7 kausal28",
    "text": "2.7 kausal28\n\nAL\n\n\n\n\n\n\n\nGegeben sei der DAG g (s. u.). Der DAG verf√ºgt √ºber mehrere Variablen, die als Knoten im Graph dargestellt sind und mit \\(x_1, x_2, \\ldots x_n\\) bezeichnet sind.\nWelche minimale Variablenmenge muss kontrolliert werden, um den kausalen Effekt von der UV zur AV zu identifizieren?\nUV: x7.\nAV: x8.\nHinweise:\n\nMengen sind mittels geschweifter Klammern gekennzeichnet, z.B. {x8, x9} meint die Menge mit den zwei Elementen x8 und x9.\nDie leere Menge { } bedeutet, dass keine Variable kontrolliert werden muss, um den kausalen Effekt zu identifizieren.\nAlle Variablen werden als gemessen vorausgesetzt.\nEs ist m√∂glich, dass es keine L√∂sung gibt, dass es also keine Adjustierungsmenge gibt, um den kausalen Effekt zu identifizieren. Wenn dies der Fall sein sollte, w√§hlen Sie ‚Äúkeine L√∂sung‚Äù.\n\n\n2.8 Answerlist\n\n{ x1 , x2 , x3 , x4 , x5 , x6 }\n{ x3, x4 }\n{ x8 }\n{ x6, x7 }\n{ x2, x5 }\n\n\n\n\nDer DAG wirkt auf den ersten Blick sehr √ºberfordernd, aber ist gar nicht schwer zu l√∂sen. Es gibt einen direkten kausalen Pfad von x7 auf x8. Schaut man sich den DAG jetzt genauer an, dann sieht man dass es f√ºr jede Zwischenvariable einen einzelnen Pfad gibt, hei√üt z.B. es gibt einen einzelnen Pfad der nur √ºber x5 oder nur √ºber x3 f√ºhrt. Alle diese Variablen sinf f√ºr diese Pfade auch Confunder, also m√ºssen wir alle Zwischenvariablen kontrollieren.\nDie L√∂sung ist also: { x1 , x2 , x3 , x4 , x5 , x6 }"
  },
  {
    "objectID": "DAGs.html#answerlist-2",
    "href": "DAGs.html#answerlist-2",
    "title": "2¬† Theorie zu DAGs",
    "section": "2.8 Answerlist",
    "text": "2.8 Answerlist\n\n{ x1 , x2 , x3 , x4 , x5 , x6 }\n{ x3, x4 }\n{ x8 }\n{ x6, x7 }\n{ x2, x5 }"
  },
  {
    "objectID": "Aufg_Wahrscheinlichkeiten.html",
    "href": "Aufg_Wahrscheinlichkeiten.html",
    "title": "3¬† Wahrscheinlichkeiten",
    "section": "",
    "text": "4 \\[W(\\neg B) = \\frac{30}{78} = 0.38\\] \\[W(A) = \\frac{42}{78} = 0.54\\]\n\\[W(A) = \\frac{42}{78} = 0.54\\] \\[W(\\neg B) = \\frac{30}{78} = 0.38\\]"
  },
  {
    "objectID": "Aufg_Wahrscheinlichkeiten.html#aufgabe-1",
    "href": "Aufg_Wahrscheinlichkeiten.html#aufgabe-1",
    "title": "3¬† Wahrscheinlichkeiten",
    "section": "3.1 Aufgabe 1",
    "text": "3.1 Aufgabe 1\n\nA1L1\n\n\nGeben Sie den Ereignisraum f√ºr das Werfen eines W√ºrfels an!\n\n\n\\[\\Omega = \\{ 1,\\ 2,\\ 3,\\ 4,\\ 5,\\ 6\\}\\]\nEreignisraum: Die Menge aller Ereignisse, d.h. aller Teilmengen einer endlichen oder abz√§hlbar unendlichen Ergebnismenge."
  },
  {
    "objectID": "Aufg_Wahrscheinlichkeiten.html#aufgabe-2",
    "href": "Aufg_Wahrscheinlichkeiten.html#aufgabe-2",
    "title": "3¬† Wahrscheinlichkeiten",
    "section": "3.2 Aufgabe 2",
    "text": "3.2 Aufgabe 2\n\nA2L2\n\n\nGeben Sie f√ºr das Werfen eines W√ºrfels folgendes Ereignis A an: ‚ÄûNur ungerade Zahlen‚Äù.\n\n\n\\[A_{nur\\ ungerade\\ Zahlen} = \\{ 1,\\ 3,\\ 5\\}\\]"
  },
  {
    "objectID": "Aufg_Wahrscheinlichkeiten.html#aufgabe-3",
    "href": "Aufg_Wahrscheinlichkeiten.html#aufgabe-3",
    "title": "3¬† Wahrscheinlichkeiten",
    "section": "3.3 Aufgabe 3",
    "text": "3.3 Aufgabe 3\n\nA3L3\n\n\nBestimmen Sie durch Verwendung der klassischen Wahrscheinlichkeitsermittlung, wie gro√ü die Wahrscheinlichkeit daf√ºr ist, dass Ereignis ‚ÄûNur ungerade Zahlen‚Äù eintritt! Welche Voraussetzungen m√ºssen gegeben sein, damit die klassische Wahrscheinlichkeitsermittlung verwendet werden kann?\n\n\nDie klassische Wahrscheinlichkeitsermittlung z√§hlt, wie viele Elementarereignisse daf√ºr sorgen, dass das Ereignis ‚ÄûNur ungerade Zahlen‚Äù eintritt. Diese Anzahl wird dann geteilt, durch die Menge aller m√∂glichen Elementarereignisse, sprich alle, die im Ereignisraum Œ© vorzufinden sind. \\(W(Nur\\ ungerade\\ Zahlen ) = \\ \\frac{Anzahl\\ der\\ Elementarereignisse,\\ \\ bei\\ denen\\ \\ A\\ ein tritt}{Anzahl\\ aller\\ Elementarereignisse\\ in\\ \\Omega} = \\frac{3}{6} = 0,5\\)"
  },
  {
    "objectID": "Aufg_Wahrscheinlichkeiten.html#aufgabe-4",
    "href": "Aufg_Wahrscheinlichkeiten.html#aufgabe-4",
    "title": "3¬† Wahrscheinlichkeiten",
    "section": "3.4 Aufgabe 4",
    "text": "3.4 Aufgabe 4\n\nA4L4\n\n\nGegeben sind ein Ereignis A und ein Ereignis B:\nEreignis A: {1, 2, 3}\nEreignis B: {5, 6}\nGeben Sie die Wahrscheinlichkeit daf√ºr, dass beim Wurf eines W√ºrfels Ereignis A ODER Ereignis B eintritt!\n‚Üí gesucht: \\(W(A \\cup B)\\)\n\n\nEin Weg, um die Wahrscheinlichkeit zu ermitteln:\n\\[W(A \\cup B) = W(A) + W(B) = \\frac{3}{6} + \\frac{2}{6} = \\frac{5}{6} = 0,833\\]"
  },
  {
    "objectID": "Aufg_Wahrscheinlichkeiten.html#aufgabe-5",
    "href": "Aufg_Wahrscheinlichkeiten.html#aufgabe-5",
    "title": "3¬† Wahrscheinlichkeiten",
    "section": "3.5 Aufgabe 5",
    "text": "3.5 Aufgabe 5\n\nA5L5\n\n\nAnschlie√üend an die vorherige Aufgabe:\nErmitteln Sie die Wahrscheinlichkeit daf√ºr, dass Ereignis A oder Ereignis B eintritt, durch Nutzung des Komplement√§rereignisses.\n\n\nDas Komplement√§rereignis zu A = {1,2,3} und B = {5, 6} ist \\(P(\\overline{A} \\cup \\overline{B})\\)= {4}. Die klassische Wahrscheinlichkeitsermittlung sagt uns, dass die Wahrscheinlichkeit eine vier zu W√ºrfeln \\(\\frac{1}{6}\\) ist. Wir k√∂nnen die Wahrscheinlichkeit f√ºr das Komplement√§rereignis von 1 abziehen, um so zu ermitteln, wie es um \\(W(A \\cup B)\\) steht. \\[W(A \\cup B) = 1 - W(\\overline{A} \\cup \\overline{B}) = 1 - \\frac{1}{6} = \\frac{5}{6} = 0,833\\]"
  },
  {
    "objectID": "Aufg_Wahrscheinlichkeiten.html#aufgabe-6",
    "href": "Aufg_Wahrscheinlichkeiten.html#aufgabe-6",
    "title": "3¬† Wahrscheinlichkeiten",
    "section": "3.6 Aufgabe 6",
    "text": "3.6 Aufgabe 6\n\nA6L6\n\n\nGegeben sind ein Ereignis A und Ereignis B.\nA = {1, 2, 3}\nB = {2, 3, 4}\nGeben Sie die Wahrscheinlichkeit daf√ºr, dass beim Wurf eines W√ºrfels Ereignis A und Ereignis B eintreten!\n\n\nUm zu ermitteln, wie gro√ü die Wahrscheinlichkeit ist, dass beim Wurf eines W√ºrfels Ereignis A und Ereignis B gleichzeitig eintreten, m√ºssen wir ermitteln, welche Elementarereignisse beide Ereignisse bedingen. Das hei√üt:\nA = {1, 2, 3}\nB = {2, 3, 4}\nWenn wir eine 2 ODER eine 3 werfen, treten beide Ereignisse gleichzeitig ein. Bei einer 1 oder einer 4 jeweils nur eines, einer 5 oder 6 hingegen keines. Wir m√ºssen also lediglich die Wahrscheinlichkeit daf√ºr errechnen, dass ein Elementarereignis der Schnittmenge eintritt.\n\\[W(A \\cap B) = \\frac{1}{6} + \\frac{1}{6} = \\frac{2}{6} = 0,33\\]"
  },
  {
    "objectID": "Aufg_Wahrscheinlichkeiten.html#aufgabe-7",
    "href": "Aufg_Wahrscheinlichkeiten.html#aufgabe-7",
    "title": "3¬† Wahrscheinlichkeiten",
    "section": "3.7 Aufgabe 7",
    "text": "3.7 Aufgabe 7\n\nA7L7\n\n\nGegeben sind ein Ereignis A, ein Ereignis B und Ereignis C.\nA = {1, 2, 3}\nB = {2, 3, 4}\nC = {5}\nWie gro√ü ist die Wahrscheinlichkeit daf√ºr, dass beim Wurf eines W√ºrfels A, B und C eintreten?\n\n\nAuch hier gilt es an erster Stelle zu ermitteln, welche Schnittmenge es zwischen den Ereignissen A, B und C gibt. In diesem Beispiel f√§llt auf, dass Ereignis C keine gleichen Elementarereignisse mit A und B hat. Ist es m√∂glich, dass A, B und C gleichzeitig eintreten? Nein, denn kein Elementarereignis, das Ereignis C bedingt, bedingt auch eines der anderen Ereignisse (bzw. genauso wenig umgekehrt). Das hei√üt, in diesem Fall k√∂nnen wir sagen:\n\\[A \\cap B \\cap C = \\left\\{ \\ \\right\\} = \\varnothing\\]"
  },
  {
    "objectID": "Aufg_Wahrscheinlichkeiten.html#aufgabe-8",
    "href": "Aufg_Wahrscheinlichkeiten.html#aufgabe-8",
    "title": "3¬† Wahrscheinlichkeiten",
    "section": "3.8 Aufgabe 8",
    "text": "3.8 Aufgabe 8\nGegeben ist folgende Vierfeldertafel:\n\n\n\n\nS\n\\(\\overline{S}\\)\n\\(\\sum\\)\n\n\n\n\nM\n60\n20\n80\n\n\n\\(\\overline{M}\\)\n5\n15\n20\n\n\n\\(\\sum\\)\n65\n35\n100\n\n\n\nEreignis M betrifft alle Studis, die die Matheklausur bestanden haben.\nEreignis \\(\\neg\\)M sind diejenigen, die die Matheklausur nicht bestanden haben.\nEreignis S betrifft alle Studis, die die Statistikklausur bestanden haben.\nEreignis \\(\\neg\\)S sind diejenigen, die die Statistikklausur nicht bestanden haben.\nIn einer Vorlesung mit allen 100 Klausurteilnehmern rufen wir willk√ºrlich jemanden auf.\n\n3.8.1 Aufgabe 8 a)\n\nA8 a)L8 a)\n\n\nWie gro√ü ist die Wahrscheinlichkeit, einen Studierenden aufzurufen, der die Matheklausur bestanden hat?\n\n\nEs haben 80 Studis die Matheklausur bestanden. Das hei√üt bei allen 100 Studis, haben wir eine 80-prozentige Wahrscheinlichkeit, jemanden zu erwischen, der in Mathe durchgekommen ist.\nRechnerisch:\n\\[W(M) = \\frac{Anzahl\\ an\\ Studis,\\ f√ºr\\ die\\ M\\ gilt}{Gesamtzahl\\ der\\ Studis} = \\frac{80}{100} = 0,8\\] Hierbei handelt es sich um eine sogenannte Randwahrscheinlichkeit.\n\n\n\n\n\n3.8.2 Aufgabe 8 b)\n\nA8 b)L8 b)\n\n\nWie gro√ü ist die Wahrscheinlichkeit jemanden aufzurufen, der/die Statistik, aber nicht Mathe bestanden hat?\n\n\nInsgesamt gibt es f√ºnf Studierende, f√ºr die Ereignis S und gleichzeitig Ereignis \\(\\neg\\)M gilt. Was wir suchen, ist die Wahrscheinlichkeit daf√ºr, von allen 100 Studis einen zu erwischen, der zu diesen f√ºnf geh√∂rt.\n\\[W(S\\cap \\neg M) = \\frac{5}{100} = 0,05\\] Diese Wahrscheinlichkeit nennt sich gemeinsame Wahrscheinlichkeit."
  },
  {
    "objectID": "Aufg_Wahrscheinlichkeiten.html#aufgabe-9",
    "href": "Aufg_Wahrscheinlichkeiten.html#aufgabe-9",
    "title": "3¬† Wahrscheinlichkeiten",
    "section": "3.9 Aufgabe 9",
    "text": "3.9 Aufgabe 9\n\nA9L9\n\n\nWie gro√ü ist die Wahrscheinlichkeit einen Studi aufzurufen, der Statistik bestanden hat, gegeben, dass er Mathe bestanden hat?\nGesucht ist die Wahrscheinlichkeit: \\(W(S|M)\\).\n\nHierbei handelt es sich um eine bedingte Wahrscheinlichkeit.\nVerst√§ndnishilfe zu solchen Fragestellungen:\nWenn es hei√üt ‚Äûgegeben, dass XXX‚Äù ist damit gemeint, dass f√ºr die Zielmenge bereits ein anderes Ereignis gilt. So zum Beispiel:\nFrage: Wie gro√ü ist die Wahrscheinlichkeit einen Studi aufzurufen, der Statistik bestanden hat, gegeben, dass er Mathe bestanden hat?\n‚Üí Welcher Anteil von denen, die Mathe bestanden haben, hat Statistik bestanden?\n\nODER\n\n‚Üí Wie wahrscheinlich ist es, dass jemand Statistik bestanden hat, wenn er zu denen geh√∂rt, die Mathe bestanden haben?\nAllgemeines Muster: \\(W(A|B)\\)\n‚Üí Wie wahrscheinlich ist es, dass f√ºr jemanden A gilt, wenn er zur Gruppe B geh√∂rt?\n\n\n\nDie bedingte Wahrscheinlichkeit wird so errechnet:\n\\[W\\left(S\\middle|M\\right) = \\frac{Studis,\\ die\\ Statistik\\ und\\ Mathe\\ bestanden\\ haben}{Von\\ all\\ denen,\\ die\\ Mathe\\ bestanden\\ haben} = \\frac{W(S\\cap M)}{W(M)} = \\frac{60}{80} = 0,75\\]"
  },
  {
    "objectID": "Aufg_Wahrscheinlichkeiten.html#aufgabe-10",
    "href": "Aufg_Wahrscheinlichkeiten.html#aufgabe-10",
    "title": "3¬† Wahrscheinlichkeiten",
    "section": "3.10 Aufgabe 10",
    "text": "3.10 Aufgabe 10\n\nA10L10\n\n\nWie gro√ü ist die Wahrscheinlichkeit eine Person aufzurufen, die Mathe bestanden hat, gegeben, dass sie Statistik nicht bestanden hat?\n\n\nAnteil derer die Mathe bestanden haben, von allen, die Statistik nicht bestanden haben \\[W\\left( M \\middle| \\neg S \\right) = \\frac{20}{35} = 0,57\\]"
  },
  {
    "objectID": "Aufg_Wahrscheinlichkeiten.html#aufgabe-11",
    "href": "Aufg_Wahrscheinlichkeiten.html#aufgabe-11",
    "title": "3¬† Wahrscheinlichkeiten",
    "section": "3.11 Aufgabe 11",
    "text": "3.11 Aufgabe 11\n\nA11L11\n\n\n**F√ºr die Beziehung von Ereignis A zu B gilt folgendes:**\n\\[W\\left( A \\middle| B \\right) = W(A|\\neg B)\\] Was k√∂nnen wir auf Grundlage dieser Aussage √ºber die Beziehung zwischen A und B schlie√üen?\n\n\nDie Aussage der Gleichung lautet √ºbersetzt:\nEs ist genauso wahrscheinlich das A eintritt, wenn B eingetreten ist, wie das A eintritt, wenn B nicht eingetreten ist. Einfach gesprochen ist es f√ºr das Eintreten von A ‚Äûegal‚Äù ob B eintritt oder nicht, weil es an der Eintrittswahrscheinlichkeit von A nichts √§ndert. Nun k√∂nnen wir daraus schlie√üen, dass A und B unabh√§ngig sein m√ºssen. Praktisches Beispiel:\nWir haben eine Stichprobe an Patienten, die entweder Blutgruppe A oder B haben. Es gilt:\n\\[W(leichter\\ Krankheitsverlauf|Blutgruppe\\ A) = W(leichter\\ Krankheitsverlauf|Blutgruppe\\ B)\\] Hei√üt: Die Wahrscheinlichkeit einen leichten Krankheitsverlauf zu haben, wenn man zur Blutgruppe A geh√∂rt, ist genauso hoch, wie die Wahrscheinlichkeit einen leichten Krankheitsverlauf zu haben, wenn man zu Blutgruppe B geh√∂rt. Das hei√üt, es ist egal, ob ein Patient Blutgruppe A oder B hat, die Wahrscheinlichkeit, einen leichten Krankheitsverlauf zu haben, bleibt die gleiche und wird somit nicht von der Blutgruppe bestimmt."
  },
  {
    "objectID": "Aufg_Wahrscheinlichkeiten.html#aufgabe-12",
    "href": "Aufg_Wahrscheinlichkeiten.html#aufgabe-12",
    "title": "3¬† Wahrscheinlichkeiten",
    "section": "3.12 Aufgabe 12",
    "text": "3.12 Aufgabe 12\nExtraaufgaben f√ºr bedingte Wahrscheinlichkeit\n\n\n\n\n\n\n\n\n\nEreignis\nBestanden (B)\nnicht bestanden (¬¨B)\nSumme\n\n\nhat gelernt (A)\n36\n6\n42\n\n\nhat nicht gelernt (¬¨A)\n12\n24\n36\n\n\nSumme\n48\n30\n78\n\n\n\n\nWir haben vier m√∂gliche Ereignisse:\nEreignis A: Eine Person hat gelernt.\nEreignis ¬¨A: Eine Person hat nicht gelernt.\nEreignis B: Eine Person hat bestanden\nEreignis ¬¨B: Eine Person hat nicht bestanden\n\n\nEs gibt verschiedene Fakten, die wir aus der Kontingenztabelle relativ einfach ablesen k√∂nnen:\n\n\n78 Personen haben an der Klausur teilgenommen\n42 Personen haben f√ºr die Klausur gelernt\n36 Personen haben nicht f√ºr die Klausur gelernt\n48 Personen haben die Klausur bestanden\n30 Personen haben die Klausur nicht bestanden\n\n\n3.12.1 Aufgabe 12 a)\n\nA12 a)L12 a)\n\n\nWie gro√ü ist die Wahrscheinlichkeit, dass eine Person nicht bestanden hat?\n\n\n\n\n\n\n\n\n\n\n\n4.0.1 Aufgabe 12 b)\n\nA12 b)L12 b)\n\n\nWie wahrscheinlich ist es, dass eine Person bestanden hat, obwohl sie nicht gelernt hat?\nWie wahrscheinlich ist es, dass eine Person gelernt hat, gegeben, dass sie bestanden hat?\n\n\n\\[W(B|\\neg A) = \\frac{12}{36} = 0.33\\] \\[W(B|A) = \\frac{36}{48} = 0.75\\]\n\n\n\n\n\n4.0.2 Aufgabe 12 c)\n\nA12 c)L12 c)\n\n\nWie wahrscheinlich ist es, dass eine Person bestanden und gelernt hat?\nWie wahrscheinlich ist es, dass eine Person nicht gelernt und nicht bestanden hat?\n\n\n\\[W(B\\cap A) = \\frac{36}{78} = 0.46\\] \\[W(\\neg A\\cap\\neg B) = \\frac{24}{78} = 0.31\\]\n\n\n\n\n\nRandwahrscheinlichkeit: Anteil an Personen, auf die ein Ereignis (z.B. A, hat gelernt) zutrifft, von der Gesamtheit aller Personen\n\n\nBedingte Wahrscheinlichkeit: Anteil an Personen, auf die ein Ereignis zutrifft (z.B. A, hat gelernt), von denjenigen auf die ein anderes Ereignis (z.B. B, hat bestanden) bereits zutrifft\n\nWie viele von denen, die bestanden haben (Ereignis B), haben auch gelernt (A)?\nWie viele haben gelernt (A), von denen die bestanden haben (B)?\n\n\n\n\nGemeinsame Wahrscheinlichkeit: Anteil an Personen, auf die zwei Ereignisse zutreffen (z.B. A und B, hat gelernt und bestanden) von der Gesamtheit aller Personen"
  },
  {
    "objectID": "Aufg_Verteilungen.html#achtung",
    "href": "Aufg_Verteilungen.html#achtung",
    "title": "4¬† Verteilungen",
    "section": "4.1 Achtung",
    "text": "4.1 Achtung\nDadurch dass die Modelle bzw. Normalverteilungen bei jeder Durchf√ºhrung neu simuliert werden, unterscheiden sich die simulierten Werte jedes Mal minimal. Unter Umst√§nden f√ºhrt dies zu leichten Abweichungen in den Dezimalstellen der Ergebnisse."
  },
  {
    "objectID": "Aufg_Verteilungen.html#aufgabe-1",
    "href": "Aufg_Verteilungen.html#aufgabe-1",
    "title": "4¬† Verteilungen",
    "section": "4.2 Aufgabe 1",
    "text": "4.2 Aufgabe 1\n\n4.2.1 Aufgabe 1 a)\n\nA1 a)L1 a)\n\n\nErstellen Sie eine Normalverteilung in R mit einem Mittelwert von 175 und einer Standardabweichung von 10. Nennen Sie diese Verteilung ‚ÄúGr√∂√üe‚Äù. Simulieren Sie hunderttausend F√§lle.\n\n\n\nset.seed(42)\n\nGr√∂√üe &lt;-\n  tibble(#Erstelle eine Tabelle\n    Verteilung = rnorm(#Erstelle mit rnorm eine Normalverteilung\n      1e5,#Insgesamt soll diese Verteilung Hunderttausend Werte haben\n                     mean = 175,#Mittelwert dieser Menge sind 175 Zentimeter\n                     sd = 10))#Die Werte streuen mit einer Standardabweichung von 10 Zentimetern\n\n\n\n\n\n\n4.2.2 Aufgabe 1 b)\n\nA1 b)L1 b)\n\n\nStellen Sie diese Verteilung graphisch dar.\n\n\n\nggplot(Gr√∂√üe, mapping = aes(x = Verteilung))+\n         geom_density()\n\n\n\n\n\n\n\n\n\n4.2.3 Aufgabe 1 c)\n\nA1 c)LA1 c)\n\n\nWie viele Menschen haben eine K√∂rpergr√∂√üe unter 175? Wie gro√ü ist dieser Anteil in Prozent?\n\n\n\nGr√∂√üe%&gt;%\n  filter(Verteilung &lt; 175)%&gt;%\n  count()\n\n\n\n  \n\n\n\nEs liegen rund 50000 Werte unterhalb von 175. Das hei√üt, von der Gesamtzahl an Menschen, die in der Verteilung erfasst worden sind, sind 50000 von 100000 kleiner als 175. Das entspricht 50 %.\n\n\n\n\n\n4.2.4 Aufgabe 1 d)\n\nA1 d)L1 d)\n\n\nWie gro√ü ist der Anteil an Menschen in der Verteilung, der gr√∂√üer ist als 150 Zentimeter?\n\n\n\nGr√∂√üe%&gt;%\n  filter(Verteilung &gt; 150)%&gt;%\n  count()\n\n\n\n  \n\n\n\nIn dieser Verteilung sind ungef√§hr 99500 Personen, also ein Anteil von 99,5% gr√∂√üer als 150.\n\n\n\n\n\n4.2.5 Aufgabe 1 e)\n\nA1 e)L1 e)\n\n\nWenn wir aus der Stichprobe irgendeine Person nehmen‚Ä¶ Wie gro√ü ist dann die Wahrscheinlichkeit, dass sie zwischen 165 und 185 gro√ü ist?\n\n\n\nGr√∂√üe%&gt;%\n  filter(Verteilung &gt; 165)%&gt;%\n  filter(Verteilung &lt; 185)%&gt;%\n  count()\n\n\n\n  \n\n\n\nDie Menge an Menschen mit einer K√∂rpergr√∂√üe zwischen 165 und 185, liegt bei rund 68000. Das hei√üt, aus den 100000 erwischen wir mit einer Wahrscheinlichkeit von 68 % einen Menschen, der innerhalb der ersten Standardabweichung (175 +- 10) liegt.\n\n\n\n\n\n4.2.6 Aufgabe 1 f)\n\nA1 f)L1 f)\n\n\nWie gro√ü ist die Wahrscheinlichkeit eine Person zu erwischen, die mit ihrer Gr√∂√üe mindestens zwei Standardabweichungen √ºber dem Durchschnitt liegt?\n\n\nEine Person die mindestens zwei Standardabweichungen √ºber dem Durchschnitt liegt‚Ä¶ Wir haben einen Durchschnitt von 175 und eine Standardabweichung von 10. Das hei√üt, wir brauchen jemanden, der mindestens 195 gro√ü ist (Gr√∂√üe &gt;= 175 + 10 + 10).\nEine Person die mindestens zwei Standardabweichungen √ºber dem Durchschnitt liegt‚Ä¶ Wir haben einen Durchschnitt von 175 und eine Standardabweichung von 10. Das hei√üt, wir brauchen jemanden, der mindestens 195 gro√ü ist (Gr√∂√üe &gt;= 175 + 10 + 10).\n\nGr√∂√üe%&gt;%\n  filter(Verteilung &gt;= 195)%&gt;%\n  summarise(Anteil = 100*(n() / 100000))\n\n\n\n  \n\n\n\nEin Anteil von fast 2 Prozent ist gr√∂√üer als 195.\n\n\n\n\n\n4.2.7 Aufgabe 1 g)\n\nA1 g)L1 g)\n\n\nIn welchem Intervall liegen grob 95% aller Werte?\n\n\nF√ºr normalverteilte Populationen gilt: Innerhalb der ersten Standardabweichung, also in unserem Fall 175 +- 10, liegen rund 68 % aller Werte. Innerhalb der zweiten Standardabweichung grob 95 % aller Werte. Innerhalb der dritten liegen 99.7 % aller Werte. F√ºr uns bedeutet das, dass der Wertebereich zwischen 155 und 195 95 % aller Werte enth√§lt.\n\nGr√∂√üe%&gt;%\n  filter(Verteilung &gt;= 155 & Verteilung &lt;= 195)%&gt;%\n  count()\n\n\n\n  \n\n\n\nWir sehen, dass tats√§chlich ungef√§hr 95.000 Werte im vermuteten Intervall liegen. Ein Beleg daf√ºr, dass es sich um ein 95-Prozent-Intervall handeln muss.\n\n\n\n\n\n4.2.8 Aufgabe 1 h)\n\nA1 h)L1 h)\n\n\n√úberlegen Sie sich drei Beispiele f√ºr Variablen, die man in einer Normalverteilung darstellen kann und simulieren Sie sie in R.\n\n\nK√∂rpergewicht in Kg:\n\nGewicht&lt;-\n  tibble(Verteilung = rnorm(1e5,\n                            mean = 70,\n                            sd = 10))\nggplot(Gewicht, mapping = aes(x = Verteilung))+\n  geom_density()\n\n\n\n\nDistanz zum Arbeitgeber in km:\n\nDistanz &lt;-\n  tibble(Verteilung = rnorm(1e5,\n                            mean = 20,\n                            sd = 5))\n\nggplot(Distanz, mapping = aes(x = Verteilung))+\n         geom_density()\n\n\n\n\nWartezeit an Bushaltestellen in Minuten:\n\nZeit&lt;-\n  tibble(Verteilung = rnorm(1e5,\n1                            mean = 7,\n2                            sd = 2.5))\n\nggplot(Zeit, mapping = aes(x = Verteilung))+\n  geom_density()+\n3  scale_x_continuous(breaks = 0:20)\n\n\n1\n\nNehmen wir an, dass Menschen an Bushaltestellen im Durchschnitt sieben Minuten warten\n\n2\n\nJedoch wartet der gr√∂√üte Teil nicht genau sieben, sondern zwischen viereinhalb bis neuneinhalb Minuten\n\n3\n\nZeige auf der x-Achse in jede einzelne Minute an"
  },
  {
    "objectID": "Aufg_Verteilungen.html#aufgabe-2",
    "href": "Aufg_Verteilungen.html#aufgabe-2",
    "title": "4¬† Verteilungen",
    "section": "4.3 Aufgabe 2",
    "text": "4.3 Aufgabe 2\n\n4.3.1 Aufgabe 2 a)\n\nA2 a)L2 a)\n\n\nErstellen Sie eine Tabelle, in der eine Spalte anhand von 10000 F√§llen zeigt, wie lange ein deutsches Auto im Durchschnitt fahrtauglich ist. Nehmen wir daf√ºr an, dass die mittlere Dauer daf√ºr 12 Jahre ist, aber diese Zahl eine Streuung von 2,5 Jahren hat.\n\n\n\nset.seed(42)\n\nPKW_Dauer &lt;-\n  tibble(Dauer = \n    rnorm(1e4, \n          mean = 12,\n          sd = 2.5))\n\n\n\n\n\n\n4.3.2 Aufgabe 2 b)\n\nA2 b)L2 b)\n\n\nWie gro√ü ist die Wahrscheinlichkeit, dass ein deutsches Auto eine unterdurchschnittliche Haltbarkeit aufweist?\n\n\n\nPKW_Dauer%&gt;%\n1  filter(Dauer &lt; mean(Dauer))%&gt;%\n2  summarise(Wahrscheinlichkeit = 100 * n()/1e4)\n\n\n1\n\nFiltere die Werte, die kleiner sind als der Durchschnitt der Spalte ‚ÄúDauer‚Äù\n\n2\n\nWenn wir den Anteil der verbliebenen Autos mit 100 multiplizieren, dann errechnen wir so einen Prozentsatz\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n4.3.3 Aufgabe 2 c)\n\nA2 c)L2 c)\n\n\nWie gro√ü ist die Wahrscheinlicheit, dass ein deutsches Auto zwischen 20 und 21 Jahre lang fahrtauglich ist?\n\n\n\nPKW_Dauer%&gt;%\n  filter(Dauer &gt; 20 & Dauer &lt; 21)%&gt;%\n  summarise(Wahrscheinlichkeit = 100 * n()/1e4)\n\n\n\n  \n\n\n\n\n\n\n\n\n4.3.4 Aufgabe 2 d)\n\nA2 d)L2 d)\n\n\nWelches Betriebsjahr erreichen 84 % der Autos nicht mehr?\n\n\nDiese Frage m√∂chte wissen, unterhalb von welchem Wert 84 % aller anderen Werte liegen. Eine M√∂glichkeit w√§re, die Tabelle zu √∂ffnen und aufsteigend zu ordnen. Dann schauen wir, welcher Wert bei der Beobachtung 8400 angegeben ist (8400 von 10000 = 84 %). Da wir aufsteigend geordnet haben, m√ºssen 84 % der Werte kleiner sein, als der, der bei 8400 angegeben ist.\nLaut der Tabelle ist dieser Wert rund 14,5. Das hei√üt 84 % der deutschen W√§gen gehen innerhalb der ersten vierzehneinhalb Jahre kaputt.\nODER wir nutzen die Quantilfunktion:\nDie Quantilfunktion macht in einfache Worten gefasst folgendes: Sie nimmt einen Anteil einer Verteilung (z.B. 84 %) und schneidet die Verteilung genau an diesem Punkt ab. D.h. sie zeigt den Wert, der gr√∂√üer ist als 84 aller anderen Werte, aber kleiner ist als die √ºbrigen 16 %. Somit bildet man das ein 84-Prozent-Quantil.\n\nPKW_Dauer%&gt;%\n  summarise(quan84 = quantile(Dauer, prob = .84))\n\n\n\n  \n\n\n\n\n\n\n\n\n4.3.5 Aufgabe 2 e)\n\nA2 e)L2 e)\n\n\nWelche Haltbarkeit wird mit einer Wahrscheinlichkeit von 95 % nicht √ºberschritten?\n\n\n\nPKW_Dauer%&gt;%\n  summarise(quan95 = quantile(Dauer, prob = .95))\n\n\n\n  \n\n\n\n\n\n\n\n\n4.3.6 Aufgabe 2 f)\n\nA2 f)L2 f)\n\n\nIn welchem Intervall liegen 90 % aller Werte?\n\n\n\nPKW_Dauer%&gt;%\n  summarise(quan5 = quantile(Dauer, prob = .05))\n\n\n\n  \n\n\n\n\nPKW_Dauer%&gt;%\n  summarise(quan95 = quantile(Dauer, prob = .95))\n\n\n\n  \n\n\n\n95 % der Autos werden ca. zwischen 8 und 16 Jahre alt."
  },
  {
    "objectID": "Aufg_Verteilungen.html#codesammlung",
    "href": "Aufg_Verteilungen.html#codesammlung",
    "title": "4¬† Verteilungen",
    "section": "4.4 Codesammlung",
    "text": "4.4 Codesammlung\n\n\n\n\n\n\nTipps f√ºr eine Codesammlung\n\n\n\n\n\nNormalverteilung erstellen\n\nnormalv &lt;-\n  tibble(\n    Verteilung = rnorm( #erstelle mit rnorm eine Normalverteilung in R\n      1e5, #insgesamt soll diese Verteilung Hunderttausend Werte haben \n                     mean = x, #Mittelwert dieser Menge \n                     sd = x)) #die Werte streuen mit einer Standardabweichung von x\n\nWie viele F√§lle liegen unter einem bestimmten Wert?\n\nnormalv%&gt;%\n  filter(Verteilung &lt; x)%&gt;%\n  count()\n\nWie viele F√§lle liegen zwischen zwei Werten?\n\nnormalv%&gt;%\n  filter(Verteilung &gt; x & Verteilung &lt; y)%&gt;%\n  count()\n\nWie gro√ü ist die Wahrscheinlichkeit, einen Fall zu erwischen, die √ºber dem Wert X liegt?\n\nnormalv%&gt;%\n  filter(Verteilung &gt; X)%&gt;%\n  summarise(Anteil = 100*(n() / 100000)) #um die Wahrscheinlichkeit direkt in Prozent zu bekommen yeah\n\nWelchen Wert erreichen x Prozent der Werte nicht mehr?\n\nnormalv%&gt;%\n  summarise(quanX = quantile(Verteilung, prob = .X))"
  },
  {
    "objectID": "Aufg_Globusversuch.html#aufgabe-1",
    "href": "Aufg_Globusversuch.html#aufgabe-1",
    "title": "5¬† Globusversuch",
    "section": "5.1 Aufgabe 1",
    "text": "5.1 Aufgabe 1\n\n5.1.1 Aufgabe 1 a)\n\nA1 a)L1 a)\n\n\nNutzen Sie die Gittermethode gegliedert in 10 Hypothesen, um herauszufinden, welcher der wahrscheinlichste Wasseranteil des Globus ist, wenn wir bei 20 Durchf√ºhrungen 14-mal Wasser getroffen haben.\n\n\n\nset.seed(42)\nd &lt;-\n  tibble(\n    p_Gitter = seq(from = 0, to = 1, by = 0.1), #Definiere die Hypothesen\n    Priori  = 1, #Bestimme die Priori-Werte\n    Likelihood = dbinom(14, size = 20, prob = p_Gitter), #Likelihood f√ºr jeden Gitterwert\n    unstd_Post = Likelihood * Priori, #unstand. Posteriori-Werte\n    Post = unstd_Post / sum(unstd_Post)) %&gt;% #stand. Posteriori-Werte (summiert zu 1)\n    mutate(\n      Post = round(Post, digits = 2)) #Runde die Posteriori-Werte auf 2 Dezimalstellen (oder eine andere gew√ºnschte Anzahl)\nd %&gt;%\n  arrange(-Post)\n\n\n\n  \n\n\n\nDer wahrscheinlichste Wasseranteil (laut unserem Modell) ist 0,7. Die Wahrscheinlichkeit betr√§gt 40 %.\n\n\n\n\n\n5.1.2 Aufgabe 1 b)\n\nA1 b)L1 b)\n\n\nWie gro√ü ist die Wahrscheinlichkeit, dass der Globus √ºber 50 Prozent Wasseranteil hat (laut unserem Modell)?\n\n\n\nd%&gt;%\n1  filter(p_Gitter &gt; 0.5)%&gt;%\n2  summarise(sum(Post))\n\n\n1\n\nZeige nur noch die Wasseranteile √ºber 50 Prozent.\n\n2\n\nDie Funktion sum() summiert alle Werte einer Spalte; in diesem Fall ist diese Spalte Post.\n\n\n\n\n\n\n  \n\n\n\nDie Wahrscheinlichkeit, dass der Wasseranteil auf dem Globus gr√∂√üer ist als 50 Prozent, liegt laut unserem Modell bei 91 %.\n\n\n\n\n\n5.1.3 Aufgabe 1 c)\n\nA1 c)L1 c)\n\n\nWie gro√ü ist die Wahrscheinlichkeit, einen Wasseranteil zwischen 50 und 70 Prozent zu erhalten?\n\n\n\nd%&gt;%\n  filter(p_Gitter &gt; .5 & p_Gitter &lt; .7)%&gt;%\n  summarise(sum(Post))\n\n\n\n  \n\n\n\nDie Wahrscheinlichkeit, dass der Wasseranteil laut unserem Modell zwischen 50 und 70 Prozent liegt, ist ca. 26 Prozent.\n\n\n\n\n\n5.1.4 Aufgabe 1 d)\n\nA1 d)L1 d)\n\n\nWie gro√ü ist die Wahrscheinlichkeit, dass der Wasseranteil 70 Prozent nicht √ºbersteigt?\n\n\n\nd%&gt;%\n  filter(p_Gitter &lt;= .7)%&gt;%\n  summarise(sum(Post))\n\n\n\n  \n\n\n\nGrob 35 Prozent der Posteriori-Verteilung liegt unterhalb eines Wasseranteils von 70 Prozent. Das hei√üt, ein Wasseranteil von 70 Prozent wird mit 35-prozentiger Wahrscheinlichkeit nicht √ºberschritten.\n\n\n\n\n\n5.1.5 Aufgabe 1 e)\n\nA1 e)L1 e)\n\n\nNehmen Sie an, Sie k√∂nnten begr√ºnden, dass ein Wasseranteil unter 50 % nicht existiert. Formen Sie die Gittermethode so, dass Werte unterhalb von 50 % Wasseranteil eine Posteriori-Wahrscheinlichkeit von 0 bekommen. Tipp: Nutzen Sie die Funktion case_when(), um den Prior zu definieren.\n\n\n\nset.seed(42)\n\nd3 &lt;-\n  tibble(\n    p_Gitter = seq(from = 0, to = 1, by = 0.1), #Definiere die Hypothesen\n    Priori  = case_when(p_Gitter &lt; 0.5 ~ 0, #F√ºr alle p_Gitter-Werte unter 0.5 gilt apriori 0\n                        p_Gitter &gt;= 0.5 ~ 1), #F√ºr alle p_Gitter-Werte √ºber oder gleich 0.5 gilt apriori 1\n    Likelihood = dbinom(14, size = 20, prob = p_Gitter), #Berechne Likelihood f√ºr jeden Gitterwert\n    unstd_Post = Likelihood * Priori, #Berechne unstand. Posteriori-Werte\n    Post = round(unstd_Post / sum(unstd_Post), 2)) #Berechne und runde stand. Posteriori-Werte\nd3"
  },
  {
    "objectID": "Aufg_Globusversuch.html#aufgabe-2",
    "href": "Aufg_Globusversuch.html#aufgabe-2",
    "title": "5¬† Globusversuch",
    "section": "5.2 Aufgabe 2",
    "text": "5.2 Aufgabe 2\nStellen Sie sich folgendes Szenario vor:\nSie wollen einen USB-Stick an Ihren Computer anschlie√üen und erwischen die falsche Seite. Kein Problem, denken Sie, dann wird es wohl die andere sein. Also drehen Sie den Stick um und probieren es mit der anderen Seite. Aber schon wieder passt es nicht! Da kann doch irgendwas nicht stimmen.\n\n5.2.1 Aufgabe 2 a)\n\nA2 a)L2 a)\n\n\nNutzen Sie die Funktion dbinom(), um zu ermitteln, wie gro√ü die Wahrscheinlichkeit ist, dass wir nur eines von f√ºnf Malen treffen, obwohl die Trefferwahrscheinlichkeit bei 50 % liegen.\n\n\n\ndbinom(1, size = 5, prob = .5)\n\n[1] 0.15625\n\n\nUnser Szenario, also dass wir eines von f√ºnf Malen treffen, hat eine Eintrittswahrscheinlichkeit von ca. 16 Prozent, wenn die Trefferchance tats√§chlich 50/50 steht. Aber wenn die Wahrscheinlichkeit so gering ist, dann kann es doch nicht sein, dass uns dieses Szenario trotzdem so regelm√§√üig passiert?\n\n\n\n\n\n5.2.2 Aufgabe 2 b)\n\nA2 b)L2 b)\n\n\nBerechnen wir ein Mal die Wahrscheinlichkeit eines von f√ºnf Malen zu treffen, wenn die Trefferahrscheinlichkeit bei 20 Prozent l√§ge.\n\n\n\ndbinom(1, 5, .2)\n\n[1] 0.4096\n\n\nDas Ergebnis sagt uns: Wenn die Trefferwahrscheinlichkeit bei 20 Prozent liegt, dann sollten wir in ca. 41 Prozent der F√§lle eines von f√ºnf Mal treffen. Scheint uns das nicht etwas plausibler? Naja, zumindest ist es wahrscheinlicher, als wenn wir eine Trefferchance von 50/50 annehmen.\n\n\n\n\n\n5.2.3 Aufgabe 2 c)\n\nA2 c)L2 c)\n\n\nDefinieren wir nun ein Modell, dass 100 Variationen der Trefferchance (d.h. 100 Paramterwerte/Hypothesen) beinhaltet. Au√üerdem schlie√üen wir von vornherein aus, dass die Trefferchance gr√∂√üer ist als 30 %.\n\n\n\nset.seed(42)\n\nUSB &lt;-\n  tibble(c_Treffer = seq(0, 1, by = 0.01),\n         Priori = case_when(c_Treffer &gt; 0.3 ~ 0,\n                            c_Treffer &lt;= 0.3 ~ 1))%&gt;%\n  mutate(Likelihood = dbinom(1, size = 5, prob = c_Treffer),\n         unst_Post = Priori * Likelihood,\n         Post = unst_Post / sum(unst_Post))\nUSB\n\n\n\n  \n\n\n\nDas Modell steht. Wir sehen, dass Beobachtungen mit einer Trefferchance von mehr als 30 % in der Post-Spalte eine Wahrscheinlichkeit von Null haben.\n\n\n\n\n\n5.2.4 Aufgabe 2 d)\n\nA2 d)L2 d)\n\n\nWie gro√ü ist die Wahrscheinlichkeit, dass die echte Trefferchance (laut unserem Modell) zwischen 12,5 % und 27,5 % liegt?\n\n\n\nUSB%&gt;%\n  filter(c_Treffer &gt; 0.125 & c_Treffer &lt; 0.275)%&gt;%\n  summarise(sum(Post))\n\n\n\n  \n\n\n\n\n\n\n\n\n5.2.5 Aufgabe 2 e)\n\nA2 e)L2 e)\n\n\nWelcher ist der wahrscheinlichste Anteil, laut unserem Modell?\n\n\n\nUSB%&gt;%\n  arrange(-Post)\n\n\n\n  \n\n\n\nNach unserem Modell ist die wahrscheinlichste Trefferchance ca. 20 Prozent. Allerdings hat diese f√ºr sich genommen nur eine Wahrscheinlichkeit von 4 %. Wir wissen allerdings auch aus Aufgabe 2d, dass sich ca. 60 % der Wahrscheinlichkeitsmasse in dem Intervall zwischen 12,5 % Trefferchance und 27,5 Prozent Trefferchance befinden.\nWir k√∂nnen also nach unserem Modell schlie√üen, dass die echte Trefferchance vermutlich sehr nahe bei 20 % liegt, allerdings mit einer Wahrscheinlichkeit von 60 Prozent, irgendwo in dem Intervall zwischen 12,5 % und 27,5 %."
  },
  {
    "objectID": "Aufg_Globusversuch.html#codesammlung",
    "href": "Aufg_Globusversuch.html#codesammlung",
    "title": "5¬† Globusversuch",
    "section": "5.3 Codesammlung",
    "text": "5.3 Codesammlung\n\n\n\n\n\n\nTipps f√ºr eine Codesammlung\n\n\n\n\n\nGitter erstellen\n\nd &lt;-\n  tibble(\n    # definiere das Gitter: \n    p_Gitter = seq(from = 0, to = 1, by = 0.1),\n    # bestimme den Priori-Wert:       \n    Priori  = 1) %&gt;%  \n    mutate(\n      # berechne Likelihood f√ºr jeden Gitterwert:\n      Likelihood = dbinom(x, size = n, prob = p_Gitter),\n      # berechen unstand. Posteriori-Werte:\n      unstd_Post = Likelihood * Priori,\n      # berechne stand. Posteriori-Werte (summiert zu 1):\n      Post = unstd_Post / sum(unstd_Post)) %&gt;%\n    mutate(\n      # Runde die Posteriori-Werte auf 2 Dezimalstellen (oder eine andere gew√ºnschte Anzahl):\n      Post = round(Post, digits = 2))  \n\nWahrscheinlichster Wert bei X Treffern von n?\n\nd %&gt;%\n  arrange(-Post)\n\nWie gro√ü ist die Wahrscheinlichkeit f√ºr Anteil von √ºber X Prozent?\n\nd%&gt;%\n  filter(p_Gitter &gt; 0.X)%&gt;% #zeige nur noch die Wasseranteile √ºber X Prozent\n  summarise(sum(Post)) #die Funktion sum() summiert alle Werte einer Spalte; in diesem Fall ist diese Spalte Post\n\nWie gro√ü ist die Wahrscheinlichkeit f√ºr einen Anteil zwischen X und Y Prozent?\n\nd%&gt;%\n  filter(p_Gitter &gt; .X & p_Gitter &lt; .Y)%&gt;%\n  summarise(sum(Post))\n\nApriori vorher definieren, Anteil unter X% existiert nicht:\n\nd2 &lt;-\n  tibble(\n    # definiere das Gitter: \n    p_Gitter = seq(from = 0, to = 1, by = 0.1),\n    # bestimme den Priori-Wert:       \n    Priori  = case_when(p_Gitter &lt; 0.X ~ 0, #alle p_Gitter-Werte unter 0.X werden mit 0 verrechnet\n                        p_Gitter &gt;= 0.X ~ 1)) %&gt;%  #alle p_Gitter-Werte √ºber oder gleich 0.X sind gleichwahrscheinlich und werden mit 1 verrechnet\n    mutate(\n      # berechne Likelihood f√ºr jeden Gitterwert:\n      Likelihood = dbinom(x, size = n, prob = p_Gitter),\n     # berechen unstand. Posteriori-Werte:\n      unstd_Post = Likelihood * Priori,\n      # berechne stand. Posteriori-Werte (summiert zu 1):\n      Post = unstd_Post / sum(unstd_Post)) %&gt;%\n    mutate(\n      # Runde die Posteriori-Werte auf 2 Dezimalstellen (oder eine andere gew√ºnschte Anzahl):\n      Post = round(Post, digits = 2))\n\nBinomialverteilung aufstellen, um die Wahrscheinlichkeit f√ºr ein bestimmtes Ereignis zu bekommen: Wie wahrscheinlich ist es, X Treffern von n zu bekommen, wenn die Trefferwahrscheinlichkeit bei Y% liegt?\n\ndbinom(x, size = n, prob = .y)"
  },
  {
    "objectID": "Aufg_Postverteilung.html#aufgabe-1",
    "href": "Aufg_Postverteilung.html#aufgabe-1",
    "title": "6¬† Postverteilung",
    "section": "6.1 Aufgabe 1",
    "text": "6.1 Aufgabe 1\n\nA1L1\n\n\nZiehen Sie eine Stichprobe mit einer Gr√∂√üe von 10.000 F√§llen. Grundlage ist der Globusversuch mit 14 von 20 Wassertreffern. Nehmen Sie an, dass Sie f√ºr 10 Hypothesen apriori indifferent sind.\n\n\n\nset.seed(42)\n\nsample1 &lt;-\n1  tibble(gitter = seq(0, 1, by = 0.1),\n         prior = 1)%&gt;%\n  mutate(likelihood = dbinom(14, size = 20, prob = gitter),\n         unst_post = prior * likelihood,\n         post = unst_post / sum(unst_post))%&gt;%\n2  slice_sample(n = 1e4,\n               weight_by = post,\n               replace = TRUE)\n\n\n1\n\nGitter erstellen\n\n2\n\nStichprobe ziehen"
  },
  {
    "objectID": "Aufg_Postverteilung.html#aufgabe-2",
    "href": "Aufg_Postverteilung.html#aufgabe-2",
    "title": "6¬† Postverteilung",
    "section": "6.2 Aufgabe 2",
    "text": "6.2 Aufgabe 2\n\nA2L2\n\n\nWie gro√ü ist die Wahrscheinlichkeit, dass der Wasseranteil gr√∂√üer als 50 Prozent ist?\n\n\n\nsample1%&gt;%\n  count(gitter &gt; .5)%&gt;%\n  mutate(Anteil = n/10000)\n\n\n\n  \n\n\n\nDie Wahrscheilichkeit, dass der Wasseranteil gr√∂√üer als 50 Prozent ist, liegt bei ~ 90 Prozent. K√ºrzer w√§re folgender Code:\n\nsample1 %&gt;% \n  summarise(Anteil = mean(gitter &gt; .5))\n\n\n\n  \n\n\n\nDie Funktion mean pr√ºft, wie viele F√§lle der Bedinung entsprechen und teilt die Anzahl dieser F√§lle durch die Gesamtanzahl aller F√§lle. Der Befehl summarise ist notwendig, um diese Information aus dem sample zu extrahieren. Den Namen der Outputspalte ‚ÄúAnteil‚Äù kann man auch weglassen."
  },
  {
    "objectID": "Aufg_Postverteilung.html#aufgabe-3",
    "href": "Aufg_Postverteilung.html#aufgabe-3",
    "title": "6¬† Postverteilung",
    "section": "6.3 Aufgabe 3",
    "text": "6.3 Aufgabe 3\n\nA3L3\n\n\nWie gro√ü ist die Wahrscheinlichkeit, dass der Wasseranteil zwischen 65 und 75 Prozent liegt?\n\n\n\nsample1%&gt;%\n  filter(gitter &gt; .65)%&gt;%\n  filter(gitter &lt; .75)%&gt;%\n  count()%&gt;%\n  summarise(`Anteil in Prozent` = n / 10000 * 100)\n\n\n\n  \n\n\n\nDie Wahrscheinlichkeit, dass der Wasseranteil zwischen 65 und 75 Prozent ist, liegt bei ~ 40 Prozent. Eleganter:\n\nsample1 %&gt;% \n  summarise(Anteil = mean(gitter &gt; .65 & gitter &lt; .75))\n\n\n\n  \n\n\n\nDas ‚Äú&‚Äù-Zeichen ist eine Und-Verkn√ºpfung. R errechnet also die Wahrscheinlichkeit f√ºr \\(P(&gt;0,65\\cap&lt;0,75)\\)."
  },
  {
    "objectID": "Aufg_Postverteilung.html#aufgabe-4",
    "href": "Aufg_Postverteilung.html#aufgabe-4",
    "title": "6¬† Postverteilung",
    "section": "6.4 Aufgabe 4",
    "text": "6.4 Aufgabe 4\n\nA4L4\n\n\nWelcher ist der mittlere Wasseranteil und wie gro√ü ist die Standardabweichung der Verteilung?\n\n\n\nsample1%&gt;%\n  summarise(`Mittlerer Wasseranteil` = mean(gitter),\n            `Standardabweichung der m√∂glichen Wasseranteile` = sd(gitter))"
  },
  {
    "objectID": "Aufg_Postverteilung.html#aufgabe-5",
    "href": "Aufg_Postverteilung.html#aufgabe-5",
    "title": "6¬† Postverteilung",
    "section": "6.5 Aufgabe 5",
    "text": "6.5 Aufgabe 5\n\nA5L5\n\n\nWelcher Wasseranteil wird mit einer Wahrscheinlichkeit von 70 Prozent nicht √ºberschritten?\n\n\n\nsample1%&gt;%\n  summarise(quant70 = quantile(gitter, prob = .7))\n\n\n\n  \n\n\n\nMit einer Wahrscheinlichkeit von 70 Prozent wird ein Wasseranteil von 70 Prozent nicht √ºberschritten."
  },
  {
    "objectID": "Aufg_Postverteilung.html#aufgabe-6",
    "href": "Aufg_Postverteilung.html#aufgabe-6",
    "title": "6¬† Postverteilung",
    "section": "6.6 Aufgabe 6",
    "text": "6.6 Aufgabe 6\n\nA6L6\n\n\nBeantworten Sie Aufgabe 5 ein weiteres Mal, ohne dabei die Funktion quantile() zu verwenden.\n\n\n\nsample1%&gt;%\n  arrange(gitter)%&gt;%\n  slice_head(n = 7000)%&gt;%\n  arrange(-gitter)\n\n\n\n  \n\n\n\nWir sehen, der gr√∂√üte Wert der Spalte gitter, nachdem wir 7000 Werte abgeschnitten haben, ist 0.7. Das hei√üt ein Wasseranteil von 0.7 muss gr√∂√üer sein, als 70 % Prozent der insgesamt 10.000 Werte."
  },
  {
    "objectID": "Aufg_Postverteilung.html#aufgabe-7",
    "href": "Aufg_Postverteilung.html#aufgabe-7",
    "title": "6¬† Postverteilung",
    "section": "6.7 Aufgabe 7",
    "text": "6.7 Aufgabe 7\n\nA7L7\n\n\nBilden Sie ein symmetrisches Perzentilinterval, das zeigt, zwischen welchen beiden Parameterwerten sich 80 Prozent der Verteilung befinden.\n\n\n\nsample1%&gt;%\n  select(gitter)%&gt;%\n  eti(ci = .8)\n\n\n\n  \n\n\n\n80 % aller Zeilen haben einen Wasseranteil von 60 bis 80 Prozent."
  },
  {
    "objectID": "Aufg_Postverteilung.html#aufgabe-8",
    "href": "Aufg_Postverteilung.html#aufgabe-8",
    "title": "6¬† Postverteilung",
    "section": "6.8 Aufgabe 8",
    "text": "6.8 Aufgabe 8\n\nA8L8\n\n\nGeben Sie die Breite des Intervalls mit der h√∂chsten Wahrscheinlichkeitsdichte, das 95 % aller Werte beinhaltet, an.\n\n\n\nsample1%&gt;%\n  select(gitter)%&gt;%\n  hdi()\n\n\n\n  \n\n\n\n\n0.50 - 0.80\n\n[1] -0.3\n\n\nDie Breite des HDI ist 0.3.\nHier noch eine andere Variante, die das Ergebnis direkt ausspuckt:\n\nsample1%&gt;%\n  select(gitter)%&gt;%\n  hdi() %&gt;% \n  mutate(width = CI_high - CI_low) %&gt;%\n  select(width)"
  },
  {
    "objectID": "Aufg_Postverteilung.html#codesammlung",
    "href": "Aufg_Postverteilung.html#codesammlung",
    "title": "6¬† Postverteilung",
    "section": "6.9 Codesammlung",
    "text": "6.9 Codesammlung\n\n\n\n\n\n\nTipps f√ºr eine Codesammlung\n\n\n\n\n\nStichprobe von 10 000 ziehen auf Basis von Gitter mit X von n Treffern\n\nset.seed(42)\n\nsample1 &lt;-\n  tibble(gitter = seq(0, 1, by = 0.1), #Gitter erstellen\n         prior = 1)%&gt;%\n  mutate(likelihood = dbinom(x, size = n, prob = gitter),\n         unst_post = prior * likelihood,\n         post = unst_post / sum(unst_post))%&gt;%\n  slice_sample(n = 1e4, #Stichprobe ziehen\n               weight_by = post,\n               replace = TRUE)\n\nWie gro√ü ist die Wahrscheinlichkeit, dass der Anteil gr√∂√üer als X% ist?\n\nsample1%&gt;%\n  count(gitter &gt; .X)%&gt;%\n  mutate(Anteil = n/10000)\n\n#ODER\nsample1 %&gt;% \n  summarise(Anteil = mean(gitter &gt; .X))\n\nMittlerer Anteil und Standardabweichung der m√∂glichen Anteile\n\nsample1%&gt;%\n  summarise(`Mittlerer Anteil` = mean(gitter),\n            `Standardabweichung der m√∂glichen Anteile` = sd(gitter))\n\nWie gro√ü ist die Wahrscheinlichkeit f√ºr einen Anteil zwischen X und Y Prozent?\n\nsample1%&gt;%\n  filter(gitter &gt; .X)%&gt;%\n  filter(gitter &lt; .Y)%&gt;%\n  count()%&gt;%\n  summarise(`Anteil in Prozent` = n / 10000 * 100)\n\n#ODER\nsample1 %&gt;% \n  summarise(Anteil = mean(gitter &gt; .65 & gitter &lt; .75))\n\nWelcher Anteil wird mit einer Wahrscheinlichkeit von X% nicht √ºberschritten?\n\nsample1%&gt;%\n  summarise(quantX = quantile(gitter, prob = .X))\n\n#OHNE quantile()\nsample1%&gt;%\n  arrange(gitter)%&gt;%\n  slice_head(n = X%*1e4)%&gt;%\n  arrange(-gitter)\n\nSymmetrisches Perzentilintervall (Equal Tails Interval = eti), dass zeigt, zwischen welchen beiden Parameterwerten sich X% der Verteilung befinden\n\nsample1%&gt;%\n  select(gitter)%&gt;%\n  eti(ci = .X) #eti steht f√ºr equal tails interval, ci f√ºr confidence interval\n\nBreite des Intervalls mit der h√∂chsten Wahrscheinlichkeitsdichte berechnen, das X% aller Werte beinhaltet:\n\n# Breite des Intervalls direkt berechnen\nsample1%&gt;%\n  select(gitter)%&gt;%\n  hdi(ci = .X) %&gt;% #hdi = high density interval = Intervall mit der h√∂chsten Wahrscheinlichkeitsdichte\n  mutate(width = CI_high - CI_low) %&gt;% #die obere Grenze des KOnfidenzintervalls von der niedrigeren abziehen, um die Breite zu bekommen\n  select(width) # nur die Breite anzeigen lassen\n\n# Intervallgrenzen ausgeben lassen (falls nach der Breite gefragt ist, m√ºsste man hier noch die beiden Grenzen voneinander abziehen)\nsample1%&gt;%\n  select(gitter)%&gt;%\n  hdi(ci = .X)"
  },
  {
    "objectID": "Aufg_Gauss-Modelle.html#aufgabe-1",
    "href": "Aufg_Gauss-Modelle.html#aufgabe-1",
    "title": "7¬† Gauss-Modelle",
    "section": "7.1 Aufgabe 1",
    "text": "7.1 Aufgabe 1\nNehmen Sie f√ºr folgende Aufgaben den Datensatz mtcars aus dem Paket datasets.\n\n7.1.1 Aufgabe 1 a)\n\nA1 a)L1 a)\n\n\nStellen Sie ein generalisiertes lineares Modell auf, das zeigt, welchen mittleren Spritverbrauch wir zu erwarten haben.\n\n\n\nset.seed(42)\nm1 &lt;- stan_glm(mpg ~ 1, data = mtcars, refresh = 0)\n\n\n\n\n\n\n7.1.2 Aufgabe 1 b)\n\nA1 b)L1 b)\n\n\nLassen Sie sich eine Zusammenfassung der Postverteilung ausgeben und geben Sie den Wert an, den das Modell am wahrscheinlichsten f√ºr den Mittelwert h√§lt. Geben Sie au√üerdem einen Bereich an, in dem laut dem Modell zu 95-prozentiger Wahrscheinlichkeit der echte Mittelwert liegt.\n\n\n\nparameters(m1)\n\n\n\n  \n\n\n\nDer Punktsch√§tzer unseres Modells ist 20, w√§hrend das Konfidenzintervall, in dem der echte Wert zu 95 Prozent liegt, von 17,95 bis 22,26 geht.\n\n\n\n\n\n7.1.3 Aufgabe 1 c)\n\nA1 c)L1 c)\n\n\nGeben Sie das Modell als Tabelle aus und visualisieren Sie die Verteilungen f√ºr den durchschnittlichen Spritverbrauch und die Streuung.\n\n\n\nm1tab &lt;-\n  m1%&gt;%\n  as_tibble()%&gt;%\n1  rename(mean = `(Intercept)`)\n\n\n1\n\nOptionale Umbenennung der Spalte (Intercept)\n\n\n\n\n\nggplot(m1tab, mapping = aes(x = mean))+\n  geom_density()\n\n\n\n\n\nggplot(m1tab, mapping = aes( x = sigma))+\n  geom_density()\n\n\n\n\n\n\n\n\n\n7.1.4 Aufgabe 1 d)\n\nA1 d)L1 d)\n\n\nGeben Sie die Wahrscheinlichkeit daf√ºr, dass der mittlere Spritverbrauch nicht gr√∂√üer ist als 21 mpg.\n\n\n\nm1tab%&gt;%\n  count(mean &lt;= 21)%&gt;%\n  mutate(Anteil = n / sum(n))\n\n\n\n  \n\n\n\nOder eleganter:\n\nm1tab %&gt;%\n  summarise(Anteil = mean(mean &lt;= 21))\n\n\n\n  \n\n\n\nDie Wahrscheinlichkeit, dass der mittlere Spritverbrauch nicht gr√∂√üer ist als 21 mpg, liegt bei ca. 80 Prozent.\n\n\n\n\n\n7.1.5 Aufgabe 1 e)\n\nA1 e)L1 e)\n\n\nWelche Streuung wird mit einer Wahrscheinlichkeit von 90 Prozent nicht √ºberschritten?\n\n\n\nm1tab%&gt;%\n  summarise(quant90 = quantile(sigma, prob = .9))\n\n\n\n  \n\n\n\nEine Streuung von 7.25 wird mit einer Wahrscheinlichkeit von 90 Prozent nicht √ºberschritten.\n\n\n\n\n\n7.1.6 Aufgabe 1 f)\n\nA1 f)L1 f)\n\n\nWie breit ist das Intervall der h√∂chsten Dichte, das angibt in welchem Bereich sich 90 Prozent der m√∂glichen Durchschnittsverbrauche befinden?\n\n\n\nm1tab%&gt;%\n  select(mean)%&gt;%\n  hdi(ci = .9)\n\n\n\n  \n\n\n21.81 - 18.23\n\n[1] 3.58\n\n\nOder eleganter:\n\nm1tab%&gt;%\n  select(mean)%&gt;%\n  hdi(ci = .9) %&gt;%\n  mutate(width = CI_high - CI_low) %&gt;% \n  select(width)\n\n\n\n  \n\n\n\nDie Breite des 90-Prozent-HDIs betr√§gt 3.58."
  },
  {
    "objectID": "Aufg_Gauss-Modelle.html#aufgabe-2",
    "href": "Aufg_Gauss-Modelle.html#aufgabe-2",
    "title": "7¬† Gauss-Modelle",
    "section": "7.2 Aufgabe 2",
    "text": "7.2 Aufgabe 2\nLaden Sie den Datensatz ‚ÄúHousePrices‚Äù aus dem gegebenen Archiv:\nhttps://vincentarelbundock.github.io/Rdatasets/datasets.html\n\nA2 a)L2 a)\n\n\nStellen Sie ein Modell auf, das zeigt mit welchem Mittelwert und welcher Streuung im Preis der H√§user zu rechnen ist.\n\n\n\nHousePrices &lt;-\n  read.csv(\"https://vincentarelbundock.github.io/Rdatasets/csv/AER/HousePrices.csv\")\n\n\nset.seed(42)\nm2 &lt;- \n  stan_glm(price ~ 1, data = HousePrices, refresh = 0)\n\n\n\n\n\n7.2.1 Aufgabe 1 b)\n\nA1 b)L1 b)\n\n\nLassen Sie sich eine Zusammenfassung der Postverteilung ausgeben und geben Sie den Wert an, den das Modell am wahrscheinlichsten f√ºr den Mittelwert h√§lt. Geben Sie au√üerdem einen Bereich an, in dem laut dem Modell zu 95-prozentiger Wahrscheinlichkeit der echte Mittelwert liegt.\n\n\n\nparameters(m2)\n\n\n\n  \n\n\n\nDer Punktsch√§tzer unseres Modells ist 68k, w√§hrend das Konfidenzintervall, in dem der echte Wert zu 95 Prozent liegt, von 65952.65 bis 70357.75 geht.\n\n\n\n\n\n7.2.2 Aufgabe 2 c)\n\nA2 c)L2 c)\n\n\nWie gro√ü ist die Wahrscheinlichkeit, dass der durchschnittliche H√§userpreis mehr als 70.000 Dollar ist?\n\n\n\nm2tab &lt;-\n  m2%&gt;%\n  as_tibble()%&gt;%\n  rename(mean = `(Intercept)`)\n\n\nm2tab%&gt;%\n  count(mean &gt; 70000)%&gt;%\n  mutate(Anteil = n / sum(n))\n\n\n\n  \n\n\n\nOder eleganter:\n\nm2tab %&gt;%\n  summarise(Anteil = mean(mean &gt; 70000))\n\n\n\n  \n\n\n\nDie Wahrscheinlichkeit, dass der mittlere H√§userpreis bei mehr als 70.000 Dollar liegt, ist laut dem Modell lediglich 5 Prozent.\n\n\n\n\n\n7.2.3 Aufgabe 2 d)\n\nA2 d)L2 d)\n\n\nWie gro√ü ist die Wahrscheinlichkeit, dass die Streuung der H√§userpreise bei 20.000 Dollar oder weniger liegt?\n\n\n\nm2tab%&gt;%\n  count(sigma &lt;= 20000)%&gt;%\n  mutate(Anteil = n / sum(n))\n\n\n\n  \n\n\n\nOder eleganter:\n\nm2tab %&gt;% \n  summarise(Anteil = mean(sigma &lt;= 20000))\n\n\n\n  \n\n\n\nDie Wahrscheinlichkeit, dass Streuung kleiner oder gleich 20000 Dollar ist, liegt laut dem Modell bei 0 Prozent.\n\n\n\n\n\n7.2.4 Aufgabe 2 e)\n\nA2 e)L2 e)\n\n\nZwischen welchen H√§userpreisen befindet sich das mittlere Intervall, dass 90 Prozent der m√∂glichen Durchschnittspreise umfasst?\n\n\n\nm2tab%&gt;%\n  select(mean)%&gt;%\n  eti(ci = .90)\n\n\n\n  \n\n\n\nLaut dem Modell werden die Grenzen des 90-Prozent-ETIs durch die Werte 66295.10 und 69988.95 gebildet."
  },
  {
    "objectID": "Aufg_Gauss-Modelle.html#codesammlung",
    "href": "Aufg_Gauss-Modelle.html#codesammlung",
    "title": "7¬† Gauss-Modelle",
    "section": "7.3 Codesammlung",
    "text": "7.3 Codesammlung\n\n\n\n\n\n\nTipps f√ºr eine Codesammlung\n\n\n\n\n\nGeneralisiertes lineares Modell aufstellen f√ºr den mittleren Wert der AV:\n\nm &lt;- stan_glm(AV ~ 1, data = data, refresh = 0)\n\nModell als Tabelle ausgeben:\n\nmtab &lt;-\n  m1%&gt;%\n  as_tibble()%&gt;%\n  rename(mean = `(Intercept)`)\n\nStreuung & Mittelwert des Modells visualiseren\n\nggplot(mtab, mapping = aes(x = mean))+\n  geom_density()\n\nggplot(mtab, mapping = aes( x = sigma))+\n  geom_density()\n\nWie gro√ü ist die Wahrscheinlichkeit daf√ºr, dass der mittlere Werte der Av nicht gr√∂√üer ist als X\n\nmtab%&gt;%\n  count(mean &lt;= X)%&gt;%\n  mutate(Anteil = n / sum(n))\n\n#ODER\nmtab %&gt;%\n  summarise(Anteil = mean(mean &lt;= X))\n\nWelche Streuung wird mit einer Wahrscheinlichkeit von X Prozent nicht √ºberschritten?\n\nmtab%&gt;%\n  summarise(quantX = quantile(sigma, prob = .X))\n\nWie gro√ü ist die Wahrscheinlichkeit, dass die Streuung der AV bei X oder weniger liegt?\n\nmtab%&gt;%\n  count(sigma &lt;= X)%&gt;%\n  mutate(Anteil = n / sum(n))\n\n#ODER\nmtab %&gt;%\n  summarise(Anteil = mean(sigma &lt;= X))"
  },
  {
    "objectID": "Aufg_Lineare-Modelle.html#aufgabe-1",
    "href": "Aufg_Lineare-Modelle.html#aufgabe-1",
    "title": "8¬† Lineare Modelle",
    "section": "8.1 Aufgabe 1",
    "text": "8.1 Aufgabe 1\n\nA1L1\n\n\nDas folgende Modell soll die Gr√∂√üe der Menschen einer Population anhand des K√∂rpergewichts vorher sagen. Welches der folgenden Modelle ist am besten f√ºr den genannten Zweck definiert?\na)\n\\[\n\\begin{aligned}\nheight_{i}\\sim Normal(\\mu_{i},\\sigma) \\\\\n\\mu_{i} = \\alpha + \\beta \\cdot weight_{i} \\\\\n\\alpha \\sim Normal(178, 20) \\\\\n\\beta \\sim Normal(0,10) \\\\\n\\sigma \\sim Exp(0.1)\n\\end{aligned}\n\\]\nb)\n\\[\n\\begin{aligned}\nheight_{i}\\sim Normal(\\mu,\\sigma)\\\\\n\\mu_{i} = \\alpha + \\beta \\cdot weight\\\\\n\\alpha \\sim Normal(178, 20)\\\\\n\\beta \\sim Normal(0,10)\\\\\n\\sigma \\sim Exp(0.1)\n\\end{aligned}\n\\]\nc)\n\\[\n\\begin{aligned}\nheight_{i}\\sim Normal(\\mu_{i},\\sigma)\\\\\n\\mu_{i} = \\alpha + \\beta \\cdot weight_{i}\\\\\n\\alpha \\sim Normal(178, 20)\\\\\n\\beta \\sim Normal(5,3)\\\\\n\\sigma \\sim Exp(0.1)\n\\end{aligned}\n\\]\nd)\n\\[\n\\begin{aligned}\nheight_{i}\\sim Normal(\\mu_{i},\\sigma)\\\\\n\\mu_{i} = \\alpha + \\beta \\cdot weight_{i}\\\\\n\\alpha \\sim Normal(178, 20)\\\\\n\\beta \\sim Normal(40,100)\\\\\n\\sigma \\sim Exp(0.1)\n\\end{aligned}\n\\]\n\n\nAntwort A:\nDie Modelldefinition der Option A ist zwar grunds√§tzlich nicht falsch, geht aber davon aus, dass der Anstieg unseres linearen Modells \\(\\beta \\sim N(0,10)\\) positiv sowie negativ sein k√∂nnte. Genauer gesagt, gibt die angegebene Normalverteilung an, dass die Wahrscheinlichkeit gleich gro√ü f√ºr positive und negative Werte ist (\\(\\mu = 0,\\pm1\\ SD = -10 bis +10\\)). Praktisch interpretiert hei√üt das: Das Modell nimmt an, dass Menschen, die immer schwerer werden, mit gleich gro√üer Wahrscheinlichkeit gr√∂√üer oder klein er werden k√∂nnten. Eine bessere Modelldefinition w√§re allerdings, dass Menschen, die immer schwerer werden auch mit gr√∂√üerer Wahrscheinlichkeit gr√∂√üer werden.\n\nAntwort B:\nModell B enth√§lt einen Formfehler. Sowohl im Likelihood als auch im linearen Modell fehlen die Beobachtungen \\(i\\). Entsprechend wird laut Modelldefinition keine konkrete Beobachtung vorhergesagt, was ja unter anderem der Sinn eines Modells ist.\n\nAntwort C:\nAntwort C ist richtig.\nW√§hrend Antwort A und C zwar beide nicht vollkommen falsch sind, kann man im Anstieg des Modells \\(\\beta\\) erkennen, dass dieser apriori √ºberwiegend positiv definiert ist. Der Priori-Anstieg geht also davon aus, dass die Gr√∂√üe einer Person zunimmt, je schwerer sie ist. Als Modell, das die Gr√∂√üe einer Person anhand des Gewichts vorhersagen soll, ist dieses von den aufgelisteten am besten geeignet.\n\nAntwort D:\nIn Modell D ist der Anstieg \\(\\beta\\) unrealistisch gro√ü definiert. Das Modell nimmt apriori an, dass es m√∂glich ist, dass ein Mensch mit einem Gewicht von \\(x=0\\) sich von einem Menschen mit \\(x=1\\) um 140 cm unterscheidet. Praktisch gesprochen:\nWenn wir die K√∂rpergr√∂√üe zweier Menschen vergleichen, die sich in ihrem K√∂rpergewicht nur um einen Kilogramm unterscheiden (Mensch 1 = 60 kg, Mensch 2 = 61 kg), dann w√§re es laut dem Modell m√∂glich, dass Mensch 2 auf Grundlage seines h√∂heren Gewichts 140 cm gr√∂√üer sein k√∂nnte als Mensch 1. Da das in der Realit√§t aber (fast) nie der Fall sein wird, handelt es sich um keine plausible Annahme."
  },
  {
    "objectID": "Aufg_Lineare-Modelle.html#aufgabe-2",
    "href": "Aufg_Lineare-Modelle.html#aufgabe-2",
    "title": "8¬† Lineare Modelle",
    "section": "8.2 Aufgabe 2",
    "text": "8.2 Aufgabe 2\nLaden Sie f√ºr die folgenden Aufgaben den Datensatz ‚Äúkidiq‚Äù aus dem Paket rstanarm.\n\ndata(kidiq)\n\n\n8.2.1 Aufgabe 2 a)\n\nA2 a)L2 a)\n\n\nErstellen Sie ein Modell, dass den IQ von Kindern anhand des IQs der Mutter vorhersagt. Was sagt der Intercept des Modells aus?\n\n\n\nset.seed(42)\nm1a &lt;- stan_glm(kid_score ~ mom_iq, data = kidiq, refresh = 0) #Modell formulieren\nparameters(m1a)\n\n\n\n  \n\n\n\nDas Modell sagt den IQ der Kinder anhand des IQs der Mutter voraus. Der Intercept des Modells stellt wie immer den erwarteten (mittleren) y-Wert f√ºr eine Beobachtung mit x = 0 dar. Das hei√üt wir sehen den erwarteten mittleren IQ eines Kindes, von einer Mutter, die einen IQ von 0 hat. Da das in der Realit√§t nicht m√∂glich ist, ist das Modell nur begrenzt gut interpretierbar.\n\n\n\n\n\n8.2.2 Aufgabe 2 b)\n\nA2 b)L2 b)\n\n\nZentrieren Sie die Pr√§diktorvariable (x-Variable/UV) und stellen Sie ein Modell auf, das den IQ von Kindern mit zentrierten Werten vorhersagt. Wie ist der Intercept nun zu interpretieren?\n\n\n\nkidiq &lt;- \n  kidiq%&gt;%\n  mutate(mom_iq_c = mom_iq - mean(mom_iq)) #Ein Wert in der Spalte mom_iq minus den Mittelwert der Spalte mom_iq\n\n\nset.seed(42)\nm1b &lt;- stan_glm(kid_score ~ mom_iq_c, data = kidiq, refresh = 0) #Modell mit zentriertem Pr√§diktor\nparameters(m1b)\n\n\n\n  \n\n\n\nJetzt, da die Pr√§diktorvariable zentriert ist, k√∂nnen wir den Intercept besser verstehen. Nun sagt dieser aus, dass das Modell im Median einen mittleren IQ von 86,8 bei einem Kind erwartet, wenn die Mutter einen durchschnittlichen IQ hat.\n\n\n\n\n\n8.2.3 Aufgabe 2 c)\n\nA2 c)L2 c)\n\n\nInnerhalb welcher beiden Werte liegt das 90 % PI des mittleren IQs der Kinder?\n\n\n\nm1btab &lt;- m1b%&gt;% #Modell m1b als Tabelle ausgeben\n  as_tibble()\n\n\nm1btab%&gt;%\n  select(`(Intercept)`)%&gt;%\n  eti(ci = .9)\n\n\n\n  \n\n\n\n\n\n\n\n\n8.2.4 Aufgabe 2 d)\n\nA2 d)L2 d)\n\n\nWelcher Wert bildet die Unsicherheit hinsichtlich des mittleren IQs der Kinder am Intercept ab?\n\n\n\nm1b\n\nstan_glm\n family:       gaussian [identity]\n formula:      kid_score ~ mom_iq_c\n observations: 434\n predictors:   2\n------\n            Median MAD_SD\n(Intercept) 86.8    0.8  \nmom_iq_c     0.6    0.1  \n\nAuxiliary parameter(s):\n      Median MAD_SD\nsigma 18.3    0.6  \n\n------\n* For help interpreting the printed output see ?print.stanreg\n* For info on the priors used see ?prior_summary.stanreg\n\n\nWenn man sich den Output des Modells anguckt, sieht man, dass der mittlere IQ der Kinder am Intercept einen Median von 86.8 hat. Allerdings hat die Verteilung auch eine mediane Standardabweichung (MAD_SD) von 0.9. Der Wert der die Unsicherheit zum mittleren IQ der Kinder am Intercept darstellt, ist also 0.8.\n\n\n\n\n\n8.2.5 Aufgabe 2 e)\n\nA2 e)L2 e)\n\n\nWie gro√ü ist die Wahrscheinlichkeit, dass der Regressionskoeffizient gr√∂√üer ist als 0,65?\n\n\n\nm1btab%&gt;%\n  summarise(mean(mom_iq_c &gt; .65))\n\n\n\n  \n\n\n\nDie Wahrscheinlichkeit, dass der Anstieg gr√∂√üer ist als 0.65 liegt bei ca. 25 Prozent.\n\n\n\n\n\n8.2.6 Aufgabe 2 f)\n\nA2 f)L2 f)\n\n\nWie gro√ü ist die Wahrscheinlichkeit, dass der mittlere IQ eines Kindes, dessen Mutter f√ºnf Einheiten √ºber dem Durchschnitt liegt, gr√∂√üer ist als 90?\n\n\n\nm1btab_f &lt;-\n  m1btab%&gt;%\n  mutate(x5 = `(Intercept)` + mom_iq_c*5) #Spalte mutieren, in der man zum Intercept (x = 0), f√ºnf Einheiten von x hinzuf√ºgt\n\n\nm1btab_f%&gt;%\n  count(x5 &gt; 90)%&gt;%\n  mutate(Anteil = n / sum(n))\n\n\n\n  \n\n\n\nDie Wahrscheinlichkeit, dass der mittlere IQ eines Kindes, das von einer Mutter mit x = 5 stammt, gr√∂√üer ist als 90, liegt bei ca. 42 Prozent."
  },
  {
    "objectID": "Aufg_Lineare-Modelle.html#aufgabe-3",
    "href": "Aufg_Lineare-Modelle.html#aufgabe-3",
    "title": "8¬† Lineare Modelle",
    "section": "8.3 Aufgabe 3",
    "text": "8.3 Aufgabe 3\nLaden Sie f√ºr die folgenden Aufgaben den Datensatz ‚Äúmtcars‚Äù aus dem Paket tidyverse.\n\ndata(mtcars)\n\n\n8.3.1 Aufgabe 3 a)\n\nA3 a)L3 a)\n\n\nErstellen Sie ein Modell, dessen AV der Spriverbrauch und dessen UV das zentrierte Gewicht eines Autos ist.\n\n\n\nmtcars &lt;-\n  mtcars%&gt;%\n  mutate(weight_c = center(wt)) #Gewicht zentrieren\n\n\nset.seed(42)\nm2a &lt;-\n  stan_glm(mpg ~ weight_c, data = mtcars, refresh = 0)\nm2a\n\nstan_glm\n family:       gaussian [identity]\n formula:      mpg ~ weight_c\n observations: 32\n predictors:   2\n------\n            Median MAD_SD\n(Intercept) 20.1    0.5  \nweight_c    -5.3    0.5  \n\nAuxiliary parameter(s):\n      Median MAD_SD\nsigma 3.1    0.4   \n\n------\n* For help interpreting the printed output see ?print.stanreg\n* For info on the priors used see ?prior_summary.stanreg\n\n\n\n\n\n\n\n8.3.2 Aufgabe 3 b)\n\nA3 b)L3 b)\n\n\nWie gro√ü ist die Wahrscheinlichkeit, dass der mittlere Spritverbauch kleiner ist als 20 mpg?\n\n\n\nm2atab &lt;- \n  m2a%&gt;% #Modell als Tabelle\n  as_tibble()\n\n\nm2atab%&gt;%\n  summarise(mean(`(Intercept)` &lt; 20))\n\n\n\n  \n\n\n\nDie Wahrscheinlichkeit, dass der mittlere Spritverbrauch kleiner ist als 20 mpg, liegt bei 43 Prozent.\n\n\n\n\n\n8.3.3 Aufgabe 3 c)\n\nA3 c)L3 b)\n\n\nWie gro√ü ist die Wahrscheinlichkeit, dass eine mittlere Streuung von 3,5 nicht √ºberschritten wird?\n\n\n\nm2atab%&gt;%\n  summarise(mean(sigma &lt; 3.5))\n\n\n\n  \n\n\n\nDie Wahrscheinlichkeit, dass eine mittlere Streuung von 3,5 nicht √ºberschritten wird, liegt bei ca. 82 Prozent."
  },
  {
    "objectID": "Aufg_Lineare-Modelle.html#codesammlung",
    "href": "Aufg_Lineare-Modelle.html#codesammlung",
    "title": "8¬† Lineare Modelle",
    "section": "8.4 Codesammlung",
    "text": "8.4 Codesammlung\n\n\n\n\n\n\nTipps f√ºr eine Codesammlung\n\n\n\n\n\nParameter eines Modells anzeigen:\n\nparameters(m1)\n\nUV zentrieren:\n\nd &lt;- \n  d%&gt;%\n  mutate(uv_c = uv - mean(uv)) \n\nX % PI angeben\n\n# Wichtig: Erst in Tabelle umwandeln!\nm1tab &lt;- m1%&gt;%\n  as_tibble()\n\nm1tab%&gt;%\n  select(`(Intercept)`)%&gt;%\n  eti(ci = .X)\n\nWahrscheinlichkeit, dass Regressionskoeffizient gr√∂√üer als X ist:\n\nm1tab%&gt;%\n  summarise(mean(uv_c &gt; X))\n\nWahrscheinlichkeit, dass der mittlere Wert der AV, wenn die UV X Einheiten √ºber dem Durchschnitt liegt, gr√∂√üer als Y ist\n\nm1tab_f &lt;-\n  m1btab%&gt;%\n  mutate(xX = `(Intercept)` + uv_c*5) \n\nm1tab_f%&gt;%\n  count(xX &gt; Y)%&gt;%\n  mutate(Anteil = n / sum(n))\n\nWahrscheinlichkeit, dass die mittlere Streuung von X nicht √ºberschritten wird\n\nm1tab%&gt;%\n  summarise(mean(sigma &lt; X))"
  },
  {
    "objectID": "Aufg_Metrische_AV.html#aufgabe-1",
    "href": "Aufg_Metrische_AV.html#aufgabe-1",
    "title": "9¬† Forschungsfragen mit metrischer AV",
    "section": "9.1 Aufgabe 1",
    "text": "9.1 Aufgabe 1\nDer Datensatz kidiq dient als Grundlage zur Beantwortung der folgenden Aufgabe. Er findet sich im Paket rstanarm. Informationen zum Datensatz lassen sich mit der Funktion ?rstanarm( ) ausgeben.\n\nA1 a)L1 a)\n\n\nStellen Sie ein Modell auf, dass den IQ eines Kindes anhand des Highschoolabschluss der Mutter vorhersagt.\nAV - kid_score UV - mom_hs\nWie gro√ü ist der mediane Unterschied zwischen dem mittleren IQ, wenn man die Kinder von einer Mutter mit und einer Mutter ohne Highschoolabschluss vergleicht?\n\n\n\ndata(kidiq)\n\nset.seed(42)\nm1 &lt;- stan_glm(kid_score ~ mom_hs, data = kidiq, refresh = 0)\nparameters(m1)\n\n\n\n  \n\n\n\nDer mediane Unterschied im mittleren IQ der Kinder von einer Mutter mit und einer Mutter ohne Highschoolabschluss betr√§gt laut dem Modell 11.75.\n\n\n\n\nA1 b)L1 b)\n\n\nBerechnen Sie dieses Modell:\nAV - kid_score UV - mom_hs, mom_age, mom_iq\nWie breit ist das 90-Prozent-HDI, das den Unterschied zwischen der mittleren Intelligenz von Kindern zeigt, wenn diese von zwei M√ºttern verschiedenen Highschoolabschlusses, gleichen Alters und gleicher Intelligenz stammen?\n\n\n\nset.seed(42)\nm6 &lt;- stan_glm(kid_score ~ mom_hs + mom_age + mom_iq, data = kidiq, refresh = 0)\n\n\nhdi(m6, ci = .9) %&gt;% \nmutate(width = CI_high - CI_low)\n\n\n\n  \n\n\n\nDer Unterschied zwischen der mittleren Intelligenz von Kindern, wenn deren M√ºtter verschiedene Abschl√ºsse, aber gleichen Alters und gleicher Intelligenz sind, betr√§gt 7.42.\n\n\n\n\nA1 c)L1 b)\n\n\nZentrieren Sie die Pr√§diktoren mom_age und mom_iq und erstellen Sie das genannte Modell mit diesen zentrierten Pr√§diktoren.\n\n\n\nkidiq2 &lt;-\n  kidiq%&gt;%\n  mutate(mom_age_c = mom_age - mean(mom_age),\n         mom_iq_c = mom_iq - mean(mom_iq))\n\n\nset.seed(42)\nm6b &lt;- stan_glm(kid_score ~ mom_hs + mom_age_c + mom_iq_c, data = kidiq2, refresh = 0)\n\n\n\n\n\nA1 d)L1 d)\n\n\nWie gro√ü ist die Wahrscheinlichkeit, dass der mittlere IQ eines Kindes gr√∂√üer ist als 85, wenn die Mutter KEINEN Highschoolabschluss sowie durchschnittliches Alter und IQ hat?\n\n\n\nm6b%&gt;%\n  as_tibble()%&gt;%\n  count(`(Intercept)` &gt; 85)%&gt;%\n  mutate(Anteil = n / sum(n))\n\n\n\n  \n\n\n\nDie Wahrscheinlichkeit, dass die gefragten Bedingungen zustimmen, liegt bei ca. 9,4 Prozent.\n\n\n\n\nA1 e)L1 e)\n\n\nWie gro√ü ist die Wahrscheinlichkeit, dass der mittlere IQ eines Kindes gr√∂√üer ist als 85, wenn die Mutter EINEN Highschoolabschluss sowie durchschnittliches Alter und IQ hat?\n\n\n\nm6btab &lt;- m6b%&gt;%\n  as_tibble()%&gt;%\n  mutate(Mit_Highschoolabschluss = `(Intercept)` + mom_hs) \n\nWir steigern an dieser Stelle nur Mom_hs vom Ausgangspunkt ‚Äúkein HS-Abschluss‚Äù (x = 0 -&gt; Intercept) zum gew√ºnschten Wert ‚Äúmit HS-Abschluss (x = 1; Intercept + Koeffizient). Alle anderen Variablen bleiben konstant, d.h. dadurch, dass sie zentriert sind, entsprechen sie dem Durchschnitt.\n\nm6btab%&gt;%\n  count(Mit_Highschoolabschluss &gt; 85)%&gt;%\n  mutate(Anteil = n / sum(n))\n\n\n\n  \n\n\n\nDie Wahrscheinlichkeit, dass ein Kind von einer Mutter mit HS-Abschluss, die ein durchschnittliches Alter sowie durchschnittlichen IQ hat, einen mittleren IQ hat, der h√∂her ist als 85, liegt bei ca. 99.9 Prozent.\n\n\n\n\nA1 f)L1 f)\n\n\nBetrachten Sie nur den den Pr√§diktor mom_hs. Wie viel Prozent der Verteilung liegen au√üerhalb des ROPEs?\nK√∂nnen wir uns laut der vorgeschlagenen ROPE-Entscheidungsregel von Kruschke sicher sein, dass der Unterschied zwischen der mittleren Intelligenz von Kindern einer Mutter ohne bzw. mit Highschoolabschluss signifikant ist?\n\n\n\nrope(m6b)\n\n\n\n  \n\n\nplot(rope(m6b))\n\n\n\n\nAu√üerhalb des Ropes liegen 96,53 Prozent. Dementsprechend k√∂nnen wir uns laut der ROPE-Entscheidungsregel von Kruschke sicher sein, dass der gefragte Unterschied (kid_score|mom_hs = 0 vs.¬†kid_score|mom_hs = 1) signifikant ist."
  },
  {
    "objectID": "Aufg_Metrische_AV.html#aufgabe-2",
    "href": "Aufg_Metrische_AV.html#aufgabe-2",
    "title": "9¬† Forschungsfragen mit metrischer AV",
    "section": "9.2 Aufgabe 2",
    "text": "9.2 Aufgabe 2\nBeziehen Sie f√ºr die folgende Aufgabe den Datensatz penguins von dieser Plattform: https://vincentarelbundock.github.io/Rdatasets/articles/data.html\n\nA2 a)L2 a)\n\n\nStellen Sie ein Modell auf, dass das K√∂rpergewicht der Pinguine anhand der Ursprungsinsel der Pinguine vorhersagt.\nAV - body_mass_g UV - island\nUnterscheiden sich die Pinguine von Biscoe-Island in ihrer Gr√∂√üe signifikant von den Pinguinen, die auf den anderen Inseln beheimatet sind?\no Ja o Nein\n\n\n\npenguins &lt;- read_csv(\"https://vincentarelbundock.github.io/Rdatasets/csv/palmerpenguins/penguins.csv\")\n\nRows: 344 Columns: 9\n-- Column specification --------------------------------------------------------\nDelimiter: \",\"\nchr (3): species, island, sex\ndbl (6): rownames, bill_length_mm, bill_depth_mm, flipper_length_mm, body_ma...\n\ni Use `spec()` to retrieve the full column specification for this data.\ni Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nset.seed(42)\nm2 &lt;- stan_glm(body_mass_g ~ island, data = penguins, refresh = 0)\nm2\n\nstan_glm\n family:       gaussian [identity]\n formula:      body_mass_g ~ island\n observations: 342\n predictors:   3\n------\n                Median  MAD_SD \n(Intercept)      4717.1    46.6\nislandDream     -1004.6    76.1\nislandTorgersen -1009.6    99.1\n\nAuxiliary parameter(s):\n      Median MAD_SD\nsigma 627.1   23.8 \n\n------\n* For help interpreting the printed output see ?print.stanreg\n* For info on the priors used see ?prior_summary.stanreg\n\n\nWir k√∂nnen sehen, dass die Referenzkategorie Biscoe-Island sein muss, da die anderen beiden Inseln uns als Modellkoeffizienten gezeigt werden. Um zu pr√ºfen, ob der Unterschied im K√∂rpergewicht gro√ü genug ist, schauen wir, ob die Null (der Median des Interceps, also 4717.1) in den ersten zwei Standardabweichungen (95 Prozent der Verteilung, also -1004.6 +/- 2* 76.1 bzw. -1009.6 +/- 2* 99.1) der anderen Koeffizienten liegt.\nWir sehen, dass ‚Äúdie Null‚Äù das nicht tut, somit sch√§tzen wir, dass der Unterschied des K√∂rpergewichts der Pinguine der Biscoe-Inseln ausreichend gro√ü sein muss.\nEntsprechend ist die richtige Antwort:\no Ja\n\n\n\n\n9.2.1 Aufgabe 2b)\nBeziehen Sie f√ºr die folgende Aufgabe den Datensatz penguins von dieser Plattform: https://vincentarelbundock.github.io/Rdatasets/articles/data.html\n\nA2 b)L2 b)\n\n\nBerechnen Sie das folgende Modell\nAV - body_mass_g UVs - island, bill_length_mm\nIm Folgenden wird der Pr√§diktor island genauer betrachtet.\nWie gro√ü ist der Anteil der Verteilung der Torgersen-Insel, der innerhalb des ROPEs liegt?\n(Runden Sie auf zwei Stellen)\n\n\n\nset.seed(42)\nm3 &lt;- stan_glm(body_mass_g ~ island + bill_length_mm, data = penguins, refresh = 0)\nm3\n\nstan_glm\n family:       gaussian [identity]\n formula:      body_mass_g ~ island + bill_length_mm\n observations: 342\n predictors:   4\n------\n                Median MAD_SD\n(Intercept)     1227.8  246.3\nislandDream     -919.2   61.2\nislandTorgersen -522.4   84.5\nbill_length_mm    77.1    5.3\n\nAuxiliary parameter(s):\n      Median MAD_SD\nsigma 493.8   19.3 \n\n------\n* For help interpreting the printed output see ?print.stanreg\n* For info on the priors used see ?prior_summary.stanreg\n\nrope(m3)\n\n\n\n  \n\n\nplot(rope(m3))\n\n\n\n\nDer Anteil der innerhalb des ROPEs liegt betr√§gt 0,00.\n\n\n\n\n\n9.2.2 Aufgabe 2 c)\nBeziehen Sie f√ºr die folgende Aufgabe den Datensatz penguins von dieser Plattform: https://vincentarelbundock.github.io/Rdatasets/articles/data.html\n\nA2 c)L2 c)\n\n\nBerechnen Sie folgendes Modell:\nAV - body_mass_g UV - bill_length_mm\nWas ist der Wert des Punktsch√§tzers f√ºr eine Beobachtung, bei der alle Pr√§diktoren den Wert 3 aufweisen?\n\n905.3\n1339.7\n633.4\n265.3\n\n\n\n\nset.seed(42)\nm4 &lt;- stan_glm(body_mass_g ~ bill_length_mm, data = penguins, refresh = 0)\nm4\n\nstan_glm\n family:       gaussian [identity]\n formula:      body_mass_g ~ bill_length_mm\n observations: 342\n predictors:   2\n------\n               Median MAD_SD\n(Intercept)    371.5  279.0 \nbill_length_mm  87.3    6.4 \n\nAuxiliary parameter(s):\n      Median MAD_SD\nsigma 646.3   24.2 \n\n------\n* For help interpreting the printed output see ?print.stanreg\n* For info on the priors used see ?prior_summary.stanreg\n\n371.5 + 3*87.3 \n\n[1] 633.4"
  },
  {
    "objectID": "Aufg_Metrische_AV.html#aufgabe-3",
    "href": "Aufg_Metrische_AV.html#aufgabe-3",
    "title": "9¬† Forschungsfragen mit metrischer AV",
    "section": "9.3 Aufgabe 3",
    "text": "9.3 Aufgabe 3\nDer Datensatz mtcars dient als Grundlage zur Beantwortung der folgenden Aufgabe. Er findet sich im Paket tidyverse. Informationen zum Datensatz lassen sich mit der Funktion ?mtcars ausgeben.\n\nA3L3\n\n\nBerechnen Sie folgendes Modell: AV ‚Üí mpg UV ‚Üí wt, drat, disp Welcher der Pr√§diktoren hat statistisch gesehen den st√§rksten negativen Effekt auf die Zielvariable? - Wt - Drat - Disp\n\n\n\ndata(mtcars)\n\nset.seed(42)\nm5 &lt;- stan_glm(mpg ~ wt + drat + disp, data = mtcars, refresh = 0)\nm5\n\nstan_glm\n family:       gaussian [identity]\n formula:      mpg ~ wt + drat + disp\n observations: 32\n predictors:   4\n------\n            Median MAD_SD\n(Intercept) 31.2    7.4  \nwt          -3.1    1.2  \ndrat         0.8    1.5  \ndisp         0.0    0.0  \n\nAuxiliary parameter(s):\n      Median MAD_SD\nsigma 3.0    0.4   \n\n------\n* For help interpreting the printed output see ?print.stanreg\n* For info on the priors used see ?prior_summary.stanreg\n\n\nAnhand der Koeffizienten l√§sst sich noch nicht sagen, welcher Effekt der st√§rkste ist, da die Pr√§diktoren auf verschiedenen Skalen rechnen. Das bedeutet, dass eine Steigerung von x um eine Einheit, nicht f√ºr alle Pr√§diktoren gleich gro√ü ist (siehe Z-Standardisieren).\nAus dem genannten Grund, m√ºssen wir die Pr√§diktoren z-standardisieren, so dass die Einheiten der einzelnen Pr√§diktoren vergleichbar werden.\n\nmtcars2 &lt;-\n  mtcars%&gt;%\n  mutate(wt_z = scale(wt),\n         drat_z = scale(drat),\n         disp_z = scale(disp))\n\nset.seed(42)\nm5b &lt;- stan_glm(mpg ~ wt_z + drat_z + disp_z, data = mtcars2, refresh = 0)\nm5b\n\nstan_glm\n family:       gaussian [identity]\n formula:      mpg ~ wt_z + drat_z + disp_z\n observations: 32\n predictors:   4\n------\n            Median MAD_SD\n(Intercept) 20.1    0.5  \nwt_z        -3.1    1.2  \ndrat_z       0.4    0.8  \ndisp_z      -2.1    1.2  \n\nAuxiliary parameter(s):\n      Median MAD_SD\nsigma 3.0    0.4   \n\n------\n* For help interpreting the printed output see ?print.stanreg\n* For info on the priors used see ?prior_summary.stanreg\n\n\nDer Pr√§diktor mit dem st√§rksten negativen Effekt auf den Spritverbrauch ist wt."
  },
  {
    "objectID": "Aufg_Metrische_AV.html#codesammlung",
    "href": "Aufg_Metrische_AV.html#codesammlung",
    "title": "9¬† Forschungsfragen mit metrischer AV",
    "section": "9.4 Codesammlung",
    "text": "9.4 Codesammlung\n\n\n\n\n\n\nTipps f√ºr eine Codesammlung\n\n\n\n\n\nRope anzeigen & plotten\n\nrope(m1)\n\nplot(rope(m1))\n\nVariablen z-standardisieren\n\ndata%&gt;%\n  mutate(uv1_z = scale(uv1),\n         uv2_z = scale(uv2),\n         uv3_z = scale(uv3))"
  },
  {
    "objectID": "Aufg_Klausurvorbereitung.html#aufgabe-penguins",
    "href": "Aufg_Klausurvorbereitung.html#aufgabe-penguins",
    "title": "10¬† Klausurvorbereitung",
    "section": "10.1 Aufgabe Penguins",
    "text": "10.1 Aufgabe Penguins\n\nA1 a)L1 a)\n\n\nPenguins Datensatz: AV: body_mass_g\nUV1: flipper_length_mm\nUV2: bill_length_mm\nStelle ein Modell auf, das den Zusammenhang zwischen der AV und UV1 untersucht und gib den Punktsch√§tzer des Effekts an.\n\n\n\np1 &lt;-\n  stan_glm(body_mass_g ~ flipper_length_mm, data = penguins, seed = 42, refresh = 0)\nparameters(p1)\n\n\n\n  \n\n\n\nDer Punktsch√§tzer des Effekts (Effekt ist so zu verstehen, was hat einen Effekt auf unsere AV?) betr√§gt hier 49.72. Das hei√üt, dass ein Pinguin, dessen Flosse einen Millimeter l√§nger ist als die eines anderen, 49.72 g mehr wiegen wird laut unserer Prognose.\n\n\n\n\nAufgabe b)L1b\n\n\nGib den Punktsch√§tzer f√ºr eine Beobachtung an, bei der alle Regressionskoeffizienten den Wert 0 aufweisen.\n\n\n\nparameters(p1)\n\n\n\n  \n\n\n\nAlle Regressionskoeffizienten sind 0, bedeutet dass alle UVs auf 0 gesetzt werden. Erinnern wir uns kurz nochmal an die Formel f√ºr ein Gerade: y = m*x + c.¬†Wenn wir x = 0 machen, dann bleibt nur noch der Y-Achsenabschnitt (= Intercept) √ºbrig. Also ist der Punktsch√§tzer f√ºr eine Beobachtung, bei der alle Regressionskoeffizienten den Wert 0 aufweisen, -5787.35.\n\n\n\n\nAufgabe c)L1c\n\n\nGib die Breite des 90% HDI-Intervalls f√ºr den Effekt an.\n\n\n\nparameters(p1, ci_method = \"hdi\", ci = .9)\n\n\n\n  \n\n\n47.24 -   52.15\n\n[1] -4.91\n\n\nF√ºr den Effekt angeben, also wieder f√ºr unsere UV: 4.91 ist die Breite, dass Intervall ist [47.24, 52.15]\n\n\n\n\nAufgabe d)L1d\n\n\nGib den Punktsch√§tzer f√ºr den mittleren Wert des K√∂rpergewichts eines Pinguins mit durschnittlicher Flossenl√§nge an.\n\n\n\n# Neue Tabelle mit zentrierter UV erstellen\npenguins_c &lt;-\n  penguins |&gt;\n  drop_na() %&gt;%\n  mutate(flipper_length_mm_c = flipper_length_mm - mean(flipper_length_mm))\n\np2 &lt;- stan_glm(body_mass_g ~ flipper_length_mm_c, data = penguins_c, refresh = 0, seed = 42)\nparameters(p2)\n\n\n\n  \n\n\n\nEin Penguin, der eine durchschnittliche Flossenl√§nge hat, hat ein mittleres K√∂rpergewicht von 4207.22 g. Wenn man diesen Wert nochmal mit den nicht zentrierten Werten vergleicht, dann machen die Werte jetzt auf einmal viel mehr Sinn, denn vorher war das mittlere K√∂rpergewicht mit einer Flossenl√§nge von 0 mm -5787 g.\n\n\n\n\nAufgabe e)L1e\n\n\nGib den Punktsch√§tzer f√ºr den mittleren Wert des K√∂rpergewichts eines Adelie-Pinguins mit durschnittlicher Flossenl√§nge in Kilogramm an.\n\n\n\n# neue Tabelle mit nur Adelie-Pinguinen und dem Gewicht in Kilogramm erstellen\npenguins_adelie_c &lt;-\n  penguins %&gt;%\n  filter(species == \"Adelie\") %&gt;% \n  drop_na() %&gt;% \n  mutate(flipper_length_mm_c = flipper_length_mm - mean(flipper_length_mm)) %&gt;% \n  mutate(body_mass_kg = body_mass_g/1000)\n\np2 &lt;- stan_glm(body_mass_kg ~ flipper_length_mm_c, data = penguins_adelie_c, refresh = 0, seed = 42)\nparameters(p2)\n\n\n\n  \n\n\n\nDas mittlere Gewicht eines Adelie-Pinguins mit einer durchschnittlichen Flossenl√§nge betr√§gt 3.71 kg. (Adelie Pinguine scheinen im Durchschnitt etwas leichter zu sein als der Durchschnitt aller Pinguine.)"
  },
  {
    "objectID": "Aufg_Klausurvorbereitung.html#rope4",
    "href": "Aufg_Klausurvorbereitung.html#rope4",
    "title": "10¬† Klausurvorbereitung",
    "section": "10.2 rope4",
    "text": "10.2 rope4\n\nA-ropeL-rope\n\n\nIst der Unterschied zwischen M√§nnern und Frauen (Dem_gender) im Hinblick zum Zusammenhang von Stress (PSS10_avg, AV) und Neurotizismus (neu, UV) vernachl√§ssigbar klein?\nDen Datensatz k√∂nnen Sie so herunterladen (Achtung, gro√ü):\n\nosf_d_path &lt;- \"https://osf.io/cjxua/?action=download\"\n\nd &lt;- read_csv(osf_d_path)\n\n\n\nWir ziehen uns nur die 3 Spalten in eine neue Tabelle, die wir auch wirklich brauchen.\n\nd2 &lt;-\n  d %&gt;% \n  select(PSS10_avg, neu, Dem_gender)\n\nWir filtern zuerst aus der Spalte Gender nur die F√§lle f√ºr male und female, droppen dann alle NAs und erstellen anschlie√üend eine neue Spalte f√ºr Geschlecht, bei dem alle weiblichen F√§lle den Wert 1 und alle m√§nnlichen F√§lle den Wert 0 zugewiesen bekommen.\n\nd3 &lt;-\n  d2 %&gt;% \n  filter(Dem_gender %in% c(\"Female\", \"Male\")) %&gt;% \n  drop_na() %&gt;% \n  mutate( is_female = case_when(\n    Dem_gender == \"Female\" ~ 1,\n    Dem_gender == \"Male\" ~ 0)) %&gt;% \n  select(-Dem_gender)\nd3 |&gt; \n  count(is_female)\n\n\n\n  \n\n\n\n\nm1 &lt;-\n  stan_glm(PSS10_avg ~ neu + is_female + neu:is_female, \n           refresh = 0,\n           seed = 42,\n           data = d3)\nparameters(m1)\n\n\n\n  \n\n\n\n\nrope(m1)\n\nPossible multicollinearity between is_female and neu (r = 0.8), neu:is_female and neu (r = 0.86). This might lead to inappropriate results. See 'Details' in '?rope'.\n\n\n\n\n  \n\n\nplot(rope(m1))\n\nPossible multicollinearity between is_female and neu (r = 0.8), neu:is_female and neu (r = 0.86). This might lead to inappropriate results. See 'Details' in '?rope'.\n\n\n\n\n\nAntwort: Ja, der Effekt ist vernachl√§ssigbar klein! Wenn dem nicht so w√§re, dann w√§re der Effekt von neuro auf Stress abh√§ngig von der Auspr√§gung einer dritten Variable, n√§mlich vom Geschlecht der Probandis. Konkret w√ºrde das zum Beispiel hei√üen, dass die Auspr√§gung von Neuro bei M√§nnern einen st√§rken bzw. schw√§cheren Einfluss auf Stress hat als bei Frauen."
  },
  {
    "objectID": "Aufg_Klausurvorbereitung.html#penguins-stan-05",
    "href": "Aufg_Klausurvorbereitung.html#penguins-stan-05",
    "title": "10¬† Klausurvorbereitung",
    "section": "10.3 penguins-stan-05",
    "text": "10.3 penguins-stan-05\n\nA-penguins-stanL-penguins-stan\n\n\nWir untersuchen Einflussfaktoren bzw. Pr√§diktoren auf das K√∂rpergewicht von Pinguinen. In dieser Aufgabe untersuchen wir den Zusammenhang von Schnabell√§nge (als UV) und K√∂rpergewicht (als AV).\nAufgabe: Wie breit ist das 95%-ETI des Effekts, wenn Sie nur die Spezies Adelie untersuchen?\n\n\n\n# nur nach Adelie filtern\npenguins_adelie &lt;- \n  penguins %&gt;% \n  filter(species == \"Adelie\")\n\n\nm1 &lt;- stan_glm(body_mass_g ~  bill_length_mm, \n               data = penguins_adelie, \n               seed = 42, \n               refresh = 0) \n\nparameters(m1, ci = .95, ci_method = \"eti\")\n\n\n\n  \n\n\n71.63 - 118.07\n\n[1] -46.44\n\n\nEs war nach dem 95% ETI des EFFEKTS gefragt, also schauen wir wieder bei der UV nach. Das Intervall hat eine Breite von 46.44"
  },
  {
    "objectID": "Aufg_Klausurvorbereitung.html#mtcars-aufgabe",
    "href": "Aufg_Klausurvorbereitung.html#mtcars-aufgabe",
    "title": "10¬† Klausurvorbereitung",
    "section": "10.4 mtcars Aufgabe",
    "text": "10.4 mtcars Aufgabe\n\nA-mtcarsL-mtcars\n\n\nZur L√∂sung dieser Aufgabe ist folgendes lineares Modell zu berechnen: AV: mpg. UVs: hp, vs.¬†Der gew√§hlte Pr√§diktor ist die erste oben genannte UV: hp (uv1). Aufgabe: Wie hoch ist die Wahrscheinlichkeit, dass der Effekt der gew√§hlten UV gr√∂√üer ist als 0.2-SD-Einheiten der AV?\n\n\n\ndata(\"mtcars\")\ng2 &lt;-\n  stan_glm(mpg ~ hp + vs, data = mtcars, refresh = 0, seed = 42)\n\ng2_tab &lt;-\n  g2 %&gt;% \n  as_tibble()\n\ng2 # man lie√üt hier aus der Angabe ab, wie gro√ü die Standardabweichung der AV ist und nimmt diese dann mal 0.2\n\nstan_glm\n family:       gaussian [identity]\n formula:      mpg ~ hp + vs\n observations: 32\n predictors:   3\n------\n            Median MAD_SD\n(Intercept) 26.8    2.9  \nhp          -0.1    0.0  \nvs           2.7    2.0  \n\nAuxiliary parameter(s):\n      Median MAD_SD\nsigma 3.9    0.5   \n\n------\n* For help interpreting the printed output see ?print.stanreg\n* For info on the priors used see ?prior_summary.stanreg\n\n2.9*0.2 \n\n[1] 0.58\n\n#0.58\n\ng2_tab %&gt;% \n  count(hp &gt; 0.58)\n\n\n\n  \n\n\n\nDIe Wahrscheinlichkeit daf√ºr, dass der Effekt gr√∂√üer als 0.2 SD-Einheiten der AV ist, betr√§gt 0."
  },
  {
    "objectID": "Aufg_Klausurvorbereitung.html#aufgabe-rope",
    "href": "Aufg_Klausurvorbereitung.html#aufgabe-rope",
    "title": "10¬† Klausurvorbereitung",
    "section": "10.5 Aufgabe rope",
    "text": "10.5 Aufgabe rope\n\nAL\n\n\nZur L√∂sung dieser Aufgabe ist folgendes lineares Modell zu berechnen: AV: mpg. UVs: wt, hp.\nIm Folgenden wird ein Pr√§diktor aus der Menge der UV n√§her betrachtet. Der gew√§hlte Pr√§diktor ist die erste oben genannte UV: wt (uv1). Aufgabe: Geben Sie den Anteil der Stichproben der Posteriori-Verteilung an, die innerhalb des ROPE liegen!\n\n\n\ng3 &lt;-\n  stan_glm(mpg ~ wt + hp, data = mtcars, refresh = 0, seed = 42)\n\nplot(rope(g3))\n\n\n\nrope(g3)\n\n\n\n  \n\n\n\nDie Frage war nach dem Pr√§diktor wt, also lesen wir ab, wie viel Prozent innerhalb des ROPEs liegen, in diesem Fall sind das 0%. Eine m√∂gliche Antwort in Bezug auf eine Forschungsfrage k√∂nnte lauten: Die Hypothese, dass der Pr√§diktor wt einen Einfluss auf die AV mpg hat, kann angenommen werden. F√ºr hp w√ºrde hier gelten: Der Einfluss von hp auf die AV mpg ist vernachl√§ssigbar klein."
  },
  {
    "objectID": "Aufg_Klausurvorbereitung.html#denkaufgabe",
    "href": "Aufg_Klausurvorbereitung.html#denkaufgabe",
    "title": "10¬† Klausurvorbereitung",
    "section": "10.6 Denkaufgabe",
    "text": "10.6 Denkaufgabe\n\nAL\n\n\nBeziehen Sie sich auf das Regressionsmodell, f√ºr das die Ausgabe mit stan_glm() hier dargestellt ist:\n## stan_glm\n\n## family: gaussian \\[identity\\]\n\n## formula: height \\~ weight_c\n\n## observations: 346\n\n## predictors: 2\n\n## ------\n\n## Median MAD_SD\n\n## (Intercept) 154.6 0.3\n\n## weight_c 0.9 0.0\n\n## \n\n## Auxiliary parameter(s):\n\n## Median MAD_SD\n\n## sigma 5.1 0.2\nBetrachten Sie wieder folgende Beziehung (Gleichung bzw. Ungleichung):\n\\[Pr(\\text{height}_i = 155|\\text{weightcentered}_i=0, \\alpha, \\beta, \\sigma) \\quad \\Box \\quad Pr(\\text{height}_i = 156|\\text{weightcentered}_i=0, \\alpha, \\beta, \\sigma)\\]\nDie in der obigen Beziehung angegebenen Parameter beziehen sich auf das oben dargestellt Modell.\nErg√§nzen Sie das korrekte Zeichen in das Rechteck \\(\\Box\\) !\nAnswerlist\\\n\n\\(\\lt\\)\n\\(\\le\\)\n\\(\\gt\\)\n\\(\\ge\\)\n\\(=\\)\n\n\n\n\nRichtig ist: \\(\\gt\\) Antwort: Der erste Teil der Gleichung gibt die Wahrscheinlichkeit f√ºr den Punktsch√§tzer der AV an, wenn der Regressionkoeffizient den Wert x = 0 aufweist. Es soll also die Wahrscheinlichkeit daf√ºr angegeben werden, dass der Wert einer Beobachtung 155 ist. Der zweite Teil der Gleichung liest sich genauso, blo√ü dass hier die Wahrscheinlichkeit daf√ºr berechnet werden soll, dass der Wert einer Beobachtung 156 ist. Schauen wir also jetzt oben in den Output, dann sehen wir, dass der Intercept = 154.6 ist. Also ist die Wahrscheinlichkeit gr√∂√üer f√ºr den Wert 155, denn dieser Wert liegt n√§her am wahren Wert 154.6 als der Wert 156."
  },
  {
    "objectID": "Aufg_Klausurvorbereitung.html#mtcars-2",
    "href": "Aufg_Klausurvorbereitung.html#mtcars-2",
    "title": "10¬† Klausurvorbereitung",
    "section": "10.7 mtcars 2",
    "text": "10.7 mtcars 2\nUntersucht wird der Effekt des Gewichts (wt) und des Schaltgetriebes (am) auf die Reichweite (mpg) eines Autos.\n\n10.7.1 mtcars 2 a)\n\nA2 a)L2 a)\n\n\nWie gro√ü ist der Unterschied in der Reichweite zwischen einem Auto mit Automatik-Schaltung im Vergleich zu einem Auto mit manuellem Schaltgetriebe, wenn der Effekt aller anderen Pr√§diktoren null ist?\n\n\n\nm1 &lt;- stan_glm(mpg ~ wt + am, data = mtcars,\n               seed = 42,\n               refresh = 0)\nparameters(m1)\n\n\n\n  \n\n\n\nDer Intercept zeigt uns den Punktsch√§tzer f√ºr die mittlere Reichweite in mpg f√ºr ein Auto ohne Gewicht mit manuellem Schaltgetriebe an. In der Zeile am k√∂nnen wir ablesen, um wieviele Meilen pro Gallonen sich die Reichweite von Automatik-Getrieben davon unterscheidet. Das sind 0,03 Meilen. Da die Ausgabe von parameters() den Effekt der einzelnen Koeffizienten anzeigt unter der Bedingung, dass der Effekt aller anderen Koeffizienten null ist, ist das auch gleichzeitig die gesuchte Zahl.\n\n\n\n\n\n10.7.2 mtcars 2 b)\n\nA2 b)L2 b)\n\n\nIst der Unterschied zwischen Autos mit Automatik vs.¬†manueller Schaltung in Bezug auf den Effekt vom Gewicht auf die Reichweite eines Autos vernachl√§ssigbar klein?\n\n\n\nm2 &lt;- stan_glm(mpg ~ wt + am + wt:am, data = mtcars,\n               seed = 42,\n               refresh = 0)\n\n\nrope(m2)\n\n\n\n  \n\n\n\n\nplot(rope(m2))\n\n\n\n\nDer Effekt ist dadurch dass der Koeffizient wt:am zu 0% im ROPE liegt, relevant und damit nicht vernachl√§ssigbar klein. Dass ein Interaktionseffekt besteht, sieht man auch in folgendem Streudiagramm: Die Reichweite von Autos mit Automatik-Schaltung sinkt mit zunehmendem Gewicht deutlich st√§rker, als die von Autos mit manueller Schaltung.\n\nmtcars %&gt;% \n  mutate(am=factor(am)) %&gt;% \nggplot(aes(x = wt, y = mpg, color= am)) +\n  geom_point()+\n  geom_smooth(method = \"lm\") +\n  theme_minimal()+\n  scale_color_tableau(\"Nuriel Stone\")\n\n`geom_smooth()` using formula = 'y ~ x'"
  },
  {
    "objectID": "Aufg_DAG.html#aufgabe-1",
    "href": "Aufg_DAG.html#aufgabe-1",
    "title": "11¬† DAGs",
    "section": "11.1 Aufgabe 1",
    "text": "11.1 Aufgabe 1\n\nA1L1\n\n\n\n\n\n\n\nGegeben sei der DAG g (s. u.). Der DAG verf√ºgt √ºber Variablen, die als Knoten im Graph dargestellt sind (mit \\(x_1, x_2, \\ldots x_n\\) bezeichnet) und √ºber Kanten verbunden sind.\nWelche minimale Variablenmenge muss kontrolliert werden, um den kausalen Effekt von der UV zur AV zu identifizieren?\nUV: y3.\nAV: y4.\nHinweise:\n\nMengen sind mittels geschweifter Klammern gekennzeichnet, z.B. {x8, x9} meint die Menge mit den zwei Elementen x8 und x9.\nDie leere Menge { } bedeutet, dass keine Variable kontrolliert werden muss, um den kausalen Effekt zu identifizieren.\nAlle Variablen werden als gemessen vorausgesetzt.\nEs ist m√∂glich, dass es keine L√∂sung gibt, dass es also keine Adjustierungsmenge gibt, um den kausalen Effekt zu identifizieren. Wenn dies der Fall sein sollte, w√§hlen Sie ‚Äúkeine L√∂sung‚Äù.\nEs ist m√∂glich, dass einzelne Variablen keine Kanten besitzen, also keine Verbindung zu anderen Variablen (Knoten) haben.\n\nAnswerlist\\\n\n{y1, y2}\n{ }\n?\n{y2}\n{y5, y1}\n\n\n\n\nRichtige Antwort ist: {y2}\nEs gibt einen direkten kausalen Pfad. Es f√ºhrt ein Confunder Pfad √ºber x2 und einer √ºber x1 und x2. F√ºr ersteres w√§re x2 der Confunder, f√ºr den zweiten Pfad w√§re x1 der Confunder. Da beide Pfade √ºber x2 f√ºhren, reicht es nur x9 zu kontrollieren."
  },
  {
    "objectID": "Aufg_DAG.html#aufgabe-2",
    "href": "Aufg_DAG.html#aufgabe-2",
    "title": "11¬† DAGs",
    "section": "11.2 Aufgabe 2",
    "text": "11.2 Aufgabe 2\n\nA2L2\n\n\n\n\n\n\n\nGegeben sei der DAG g (s. u.). Der DAG verf√ºgt √ºber Variablen, die als Knoten im Graph dargestellt sind (mit \\(x_1, x_2, \\ldots x_n\\) bezeichnet) und √ºber Kanten verbunden sind.\nWelche minimale Variablenmenge muss kontrolliert werden, um den kausalen Effekt von der UV zur AV zu identifizieren?\nUV: x4.\nAV: x6.\nHinweise:\n\nMengen sind mittels geschweifter Klammern gekennzeichnet, z.B. {x8, x9} meint die Menge mit den zwei Elementen x8 und x9.\nDie leere Menge { } bedeutet, dass keine Variable kontrolliert werden muss, um den kausalen Effekt zu identifizieren.\nAlle Variablen werden als gemessen vorausgesetzt.\nEs ist m√∂glich, dass es keine L√∂sung gibt, dass es also keine Adjustierungsmenge gibt, um den kausalen Effekt zu identifizieren. Wenn dies der Fall sein sollte, w√§hlen Sie ‚Äúkeine L√∂sung‚Äù.\nEs ist m√∂glich, dass einzelne Variablen keine Kanten besitzen, also keine Verbindung zu anderen Variablen (Knoten) haben.\n\nAnswerlist\\\n\n{x2}\n{ }\n{x3}\n{x6, x1}\n{x1, x2}\n\n\n\n\nRichtige Antwort ist: {x1, x2}\nEs f√ºhrt sowohl ein Konfundierungspfad √ºber x1 (ohne dabei √ºber x2 zu gehen) als auch einer √ºber x2 (ohne dabei √ºber x1 zu gehen)."
  },
  {
    "objectID": "Aufg_DAG.html#aufgabe-3",
    "href": "Aufg_DAG.html#aufgabe-3",
    "title": "11¬† DAGs",
    "section": "11.3 Aufgabe 3",
    "text": "11.3 Aufgabe 3\n\nA3L3\n\n\n\n\n\n\n\nGegeben sei der DAG g (s. u.). Der DAG verf√ºgt √ºber Variablen, die als Knoten im Graph dargestellt sind (mit \\(x_1, x_2, \\ldots x_n\\) bezeichnet) und √ºber Kanten verbunden sind.\nWelche minimale Variablenmenge muss kontrolliert werden, um den kausalen Effekt von der UV zur AV zu identifizieren?\nUV: x5.\nAV: x6.\nHinweise:\n\nMengen sind mittels geschweifter Klammern gekennzeichnet, z.B. {x8, x9} meint die Menge mit den zwei Elementen x8 und x9.\nDie leere Menge { } bedeutet, dass keine Variable kontrolliert werden muss, um den kausalen Effekt zu identifizieren.\nAlle Variablen werden als gemessen vorausgesetzt.\nEs ist m√∂glich, dass es keine L√∂sung gibt, dass es also keine Adjustierungsmenge gibt, um den kausalen Effekt zu identifizieren. Wenn dies der Fall sein sollte, w√§hlen Sie ‚Äúkeine L√∂sung‚Äù.\nEs ist m√∂glich, dass einzelne Variablen keine Kanten besitzen, also keine Verbindung zu anderen Variablen (Knoten) haben.\n\nAnswerlist\\\n\n{x2}\n{ }\n{x3}\n{x4, x1}\n{x3, x4}\n\n\n\n\nRichtige Antwort ist: {x3, x4}\nx3 muss auf jeden Fall kontrolliert werden, dadurch ist auch automatisch der Pfad √ºber x1 geschlossen. Schaut man sich jetzt den Pfad √ºber x2 und x4 an, dann sieht man das der Confunder x2 ist, jedoch gibt es diese Antwortm√∂glichkeit nicht. Wir wissen aber auch, dass es egal ist welche Zwischenvariable man auf einem Confunderpfad kontrolliert, solange man eine kontrolliert. Deswegen kann man auch x4kontrollieren, um diesen Pfad zu schlie√üen."
  },
  {
    "objectID": "Aufg_DAG.html#aufgabe-4",
    "href": "Aufg_DAG.html#aufgabe-4",
    "title": "11¬† DAGs",
    "section": "11.4 Aufgabe 4",
    "text": "11.4 Aufgabe 4\n\nA4L4\n\n\n\n\n\n\n\nGegeben sei der DAG g (s. u.). Der DAG verf√ºgt √ºber Variablen, die als Knoten im Graph dargestellt sind (mit \\(x_1, x_2, \\ldots x_n\\) bezeichnet) und √ºber Kanten verbunden sind.\nWelche minimale Variablenmenge muss kontrolliert werden, um den kausalen Effekt von der UV zur AV zu identifizieren?\nUV: x4.\nAV: x6.\nHinweise:\n\nMengen sind mittels geschweifter Klammern gekennzeichnet, z.B. {x8, x9} meint die Menge mit den zwei Elementen x8 und x9.\nDie leere Menge { } bedeutet, dass keine Variable kontrolliert werden muss, um den kausalen Effekt zu identifizieren.\nAlle Variablen werden als gemessen vorausgesetzt.\nEs ist m√∂glich, dass es keine L√∂sung gibt, dass es also keine Adjustierungsmenge gibt, um den kausalen Effekt zu identifizieren. Wenn dies der Fall sein sollte, w√§hlen Sie ‚Äúkeine L√∂sung‚Äù.\nEs ist m√∂glich, dass einzelne Variablen keine Kanten besitzen, also keine Verbindung zu anderen Variablen (Knoten) haben.\n\nAnswerlist\\\n\n{x2}\n{ }\n{x1}\n{x4, x1}\n{x1, x2}\n\n\n\n\nRichtige Antwort ist: {x1}\nx1 muss auf jeden Fall kontrolliert werden, denn alle Confunder-Pfade m√ºssen zwangsl√§ufig √ºber x1 gehen. Alle Pfade, die √ºber x5 haben an dieser Stelle eine Kollision, also d√ºrfen wir hier nichts kontrollieren. Genauso haben wir einen Collider bei x3 wenn wir den Pfad von x4 √ºber x2, x3, x1 zu x6 gehen."
  },
  {
    "objectID": "Aufg_DAG.html#aufgabe-5",
    "href": "Aufg_DAG.html#aufgabe-5",
    "title": "11¬† DAGs",
    "section": "11.5 Aufgabe 5",
    "text": "11.5 Aufgabe 5\n\nA5L5\n\n\n\n\n\n\n\nGegeben sei der DAG g (s. u.). Der DAG verf√ºgt √ºber Variablen, die als Knoten im Graph dargestellt sind (mit \\(x_1, x_2, \\ldots x_n\\) bezeichnet) und √ºber Kanten verbunden sind.\nWelche minimale Variablenmenge muss kontrolliert werden, um den kausalen Effekt von der UV zur AV zu identifizieren?\nUV: x4.\nAV: x6.\nHinweise:\n\nMengen sind mittels geschweifter Klammern gekennzeichnet, z.B. {x8, x9} meint die Menge mit den zwei Elementen x8 und x9.\nDie leere Menge { } bedeutet, dass keine Variable kontrolliert werden muss, um den kausalen Effekt zu identifizieren.\nAlle Variablen werden als gemessen vorausgesetzt.\nEs ist m√∂glich, dass es keine L√∂sung gibt, dass es also keine Adjustierungsmenge gibt, um den kausalen Effekt zu identifizieren. Wenn dies der Fall sein sollte, w√§hlen Sie ‚Äúkeine L√∂sung‚Äù.\nEs ist m√∂glich, dass einzelne Variablen keine Kanten besitzen, also keine Verbindung zu anderen Variablen (Knoten) haben.\n\nAnswerlist\\\n\n{x2}\n{ }\n{x1}\n{x4, x1}\n{x1, x2}\n\n\n\n\nRichtige Antwort ist: {x1}\nx1 muss auf jeden Fall kontrolliert werden, denn alle Confunder-Pfade m√ºssen zwangsl√§ufig √ºber x1 gehen. Alle Pfade, die √ºber x5 haben an dieser Stelle eine Kollision, also d√ºrfen wir hier nichts kontrollieren. Genauso haben wir einen Collider bei x3 wenn wir den Pfad von x4 √ºber x2, x3, x1 zu x6 gehen."
  },
  {
    "objectID": "Pr√ºfungstipps.html#allgemeine-hinweise",
    "href": "Pr√ºfungstipps.html#allgemeine-hinweise",
    "title": "12¬† Tipps f√ºr die Pr√ºfung",
    "section": "12.1 Allgemeine Hinweise",
    "text": "12.1 Allgemeine Hinweise\nLest euch die Aufgaben immer genau durch und nehmt euch die Zeit daf√ºr.\nSchaut euch auch die Pr√ºfungshinweise rechtzeitig vor der Pr√ºfung an, damit ihr genau wisst, wie ihr bestimmte Angaben machen m√ºsst. (Pr√ºfungshinweise)"
  },
  {
    "objectID": "Pr√ºfungstipps.html#codesammlung",
    "href": "Pr√ºfungstipps.html#codesammlung",
    "title": "12¬† Tipps f√ºr die Pr√ºfung",
    "section": "12.2 Codesammlung",
    "text": "12.2 Codesammlung\nLegt euch auf jeden Fall eine Codesammlung f√ºr die Pr√ºfung an, in der alle wichtigen Codes vom Semester drin stehen. Dies ist besonders wichtig, damit ihr in der Pr√ºfung nicht noch √ºberlegen m√ºsst, wie der Code nochmal genau aussieht, sondern direkt in eurer Sammlung danach suchen k√∂nnt und diesen Code dann kopieren.\nWir haben euch unter jedem Kapitel die relevantesten Codes zusammengefasst, ihr k√∂nnt euch diese also alle kopieren. Trotzdem raten wir euch dazu selbst zu √ºberlegen, welche Codes wichtig sein k√∂nnten.\nStrukturiert eure Codesammlung gut und schreibt immer dazu, was der Code macht, damit ihr direkt den passenden Code zu jeder Aufgabe findet."
  },
  {
    "objectID": "Pr√ºfungstipps.html#r-studio-cloud",
    "href": "Pr√ºfungstipps.html#r-studio-cloud",
    "title": "12¬† Tipps f√ºr die Pr√ºfung",
    "section": "12.3 R Studio Cloud",
    "text": "12.3 R Studio Cloud\nR Studio Cloud Projekt\nHabt auf jeden Fall R Studio Cloud als Backup bereit, falls R Studio bei euch aus irgendeinem Grund am Tag der Pr√ºfung nicht funktioniert.\nHerr Sauer hat daf√ºr ein Projekt angelegt, indem schon alle ben√∂tigten Pakete geladen sind.\n\n\n\n\n\n\nWarning\n\n\n\nAchtung, es dauert etwas bis das Projekt geladen hat, also bereitet es schon fr√ºhzeitig vor, damit ihr notfalls direkt loslegen k√∂nnt!"
  },
  {
    "objectID": "Pr√ºfungstipps.html#klausurprojekt-vorbereiten",
    "href": "Pr√ºfungstipps.html#klausurprojekt-vorbereiten",
    "title": "12¬† Tipps f√ºr die Pr√ºfung",
    "section": "12.4 Klausurprojekt vorbereiten",
    "text": "12.4 Klausurprojekt vorbereiten\nErstellt euch f√ºr die Pr√ºfung im Vorhinein ein neues R-Projekt, in dem ihr alle pr√ºfungsrelevanten Datens√§tze abspeichert (Liste der Pr√ºfungsdatens√§tze). Wenn ihr das tut, k√∂nnt ihr bequem auf die Datens√§tze zugreifen, ohne sie extra laden zu m√ºssen. Es k√∂nnte auch hilfreich sein, ein Dokument anzulegen, in dem ihr schon Kapitel f√ºr die Aufgaben habt oder schon Code f√ºr bestimmte Aufgabentypen. Dieses Dokument kann euch als Template dienen, das ihr in der Pr√ºfung nur noch ausf√ºllen m√ºsst. Anstatt die Datens√§tze im Vorhinein abzuspeichern, k√∂nnt ihr auch einen Code-Chunk in dem Dokument vorbereiten, in dem ihr die Datens√§tze √ºber die Links importiert."
  },
  {
    "objectID": "Pr√ºfungstipps.html#dokumentation",
    "href": "Pr√ºfungstipps.html#dokumentation",
    "title": "12¬† Tipps f√ºr die Pr√ºfung",
    "section": "12.5 Dokumentation",
    "text": "12.5 Dokumentation\nAchtet w√§hrend der Pr√ºfung darauf alle eure Schritte sauber zu dokumentieren. Dies hilft euch w√§hrend der Pr√ºfung, denn teilweise m√ºsst ihr bei mehreren Aufgaben das gleiche Modell aufstellen und so spart ihr euch Rechenzeit. Auch im Nachhinein kann es euch helfen, alles gut dokumentiert zu haben, denn so k√∂nnt ihr belegen, wie ihr zu euren Ergebnissen gekommen seid.\nTrotzdem ist es wichtig, dass ihr Datens√§tze oder Modelle nie √ºberschreibt. Braucht ihr z.B. f√ºr Aufgabe 1 ein Modell, welches ihr bei Aufgabe 2 auch braucht, dann benennt es f√ºr Aufgabe 2 einfach neu, damit ihr nicht aus Versehen etwas l√∂scht und es am Ende f√ºr beide Aufgaben nochmal neu berechnen m√ºsst."
  },
  {
    "objectID": "Pr√ºfungstipps.html#zum-abschluss",
    "href": "Pr√ºfungstipps.html#zum-abschluss",
    "title": "12¬† Tipps f√ºr die Pr√ºfung",
    "section": "12.6 Zum Abschluss",
    "text": "12.6 Zum Abschluss\nGanz wichtig zum Schluss: Keine Panik!\nEs ist alles absolut machbar! Wenn ihr flei√üig die Aufgaben durchmacht und euch gut auf die Pr√ºfung mit Codesammlung und Template vorbereitet, dann wird es kein Problem f√ºr euch sein.\nWir w√ºnschen euch viel Gl√ºck und Erfolg! üçÄ"
  }
]